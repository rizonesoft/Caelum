{"version":3,"file":"commands.js","mappings":";yBAKA,IAAIA,EAmCAC,EASAC,EA+CAC,EAaAC,EAiBAC,EAiBAC,EAaAC,EA6BAC,EAYAC,EAoBAC,EA+FAC,E,6qCAlTJ,SAAWX,GAEPA,EAAmB,OAAI,SAEvBA,EAAmB,OAAI,SAEvBA,EAAoB,QAAI,UAExBA,EAAoB,QAAI,UAExBA,EAAkB,MAAI,QAEtBA,EAAmB,OAAI,QAC1B,CAbD,CAaGA,IAAeA,EAAa,CAAC,IAsBhC,SAAWC,GACPA,EAA6C,qBAAI,uBACjDA,EAA+B,OAAI,QACtC,CAHD,CAGGA,IAA2BA,EAAyB,CAAC,IAMxD,SAAWC,GAIPA,EAA6B,oBAAI,sBAIjCA,EAAoB,WAAI,aAKxBA,EAAwB,eAAI,iBAK5BA,EAAmC,0BAAI,2BAC1C,CAnBD,CAmBGA,IAAYA,EAAU,CAAC,IA4B1B,SAAWC,GACPA,EAAwC,0BAAI,4BAC5CA,EAAwC,0BAAI,4BAC5CA,EAA8C,gCAAI,kCAClDA,EAAuC,yBAAI,2BAC3CA,EAA8C,gCAAI,kCAClDA,EAA4C,8BAAI,+BACnD,CAPD,CAOGA,IAAiBA,EAAe,CAAC,IAMpC,SAAWC,GAEPA,EAAqD,iCAAI,mCAEzDA,EAAwC,oBAAI,sBAE5CA,EAA2C,uBAAI,yBAE/CA,EAAoC,gBAAI,kBAExCA,EAA+B,WAAI,YACtC,CAXD,CAWGA,IAAuBA,EAAqB,CAAC,IAMhD,SAAWC,GAEPA,EAA8C,6BAAI,+BAElDA,EAA4B,WAAI,aAEhCA,EAAqB,IAAI,MAEzBA,EAAwB,OAAI,SAE5BA,EAAsB,KAAI,MAC7B,CAXD,CAWGA,IAAoBA,EAAkB,CAAC,IAM1C,SAAWC,GAEPA,EAAwC,2BAAI,6BAE5CA,EAAoB,OAAI,SAExBA,EAAmB,MAAI,OAC1B,CAPD,CAOGA,IAAgBA,EAAc,CAAC,IAMlC,SAAWC,GAEPA,EAAwC,0BAAI,4BAE5CA,EAAmB,KAAI,OAEvBA,EAAyB,WAAI,aAE7BA,EAAqB,OAAI,SAEzBA,EAAyB,WAAI,aAE7BA,EAAuB,SAAI,WAE3BA,EAAwB,UAAI,YAE5BA,EAAiC,mBAAI,qBAErCA,EAAmB,KAAI,OAEvBA,EAAsC,wBAAI,0BAE1CA,EAAoB,MAAI,OAC3B,CAvBD,CAuBGA,IAAiBA,EAAe,CAAC,IAMpC,SAAWC,GACPA,EAAgC,sBAAI,wBACpCA,EAA0B,gBAAI,kBAC9BA,EAA6B,mBAAI,qBACjCA,EAA8B,oBAAI,sBAClCA,EAAyB,eAAI,iBAC7BA,EAAqB,WAAI,YAC5B,CAPD,CAOGA,IAAaA,EAAW,CAAC,IAK5B,SAAWC,GAEPA,EAAsC,iBAAI,mBAG1CA,EAA0B,KAAI,OAK9BA,EAAyB,IAAI,MAG7BA,EAA0B,KAAI,MACjC,CAdD,CAcGA,IAAwBA,EAAsB,CAAC,IAMlD,SAAWC,GAEPA,EAAuC,iBAAI,mBAE3CA,EAAmC,aAAI,cAC1C,CALD,CAKGA,IAAyBA,EAAuB,CAAC,IAsBdE,MAoEtC,SAAWD,GACPA,EAAuB,iBAAI,kBAC3BA,EAA8B,wBAAI,wBAClCA,EAAmB,aAAI,cACvBA,EAAoB,cAAI,eACxBA,EAA2B,qBAAI,oBAClC,CAND,CAMGA,IAASA,EAAO,CAAC,IA0QhBJ,EAAaM,WACbN,EAAaO,OACbP,EAAaQ,SAgEU,mBAApBC,iBAAiCA,gBCpmBxC,IAEMC,EAAkC,CACtCC,OAAQ,GACRC,aAAc,yBACdC,YAAa,eACbC,oBAAqB,UACrBC,gBAAiB,WAOfC,EAA+B,KAuE5B,SAASC,EAA0CC,GACxD,OA/DK,WACL,GAAIF,EAAQ,OAAAG,EAAA,GAAYH,GAExB,IACE,IAAMI,EAAMC,aAAaC,QA3BT,kBA4BhB,GAAIF,EAAK,CACP,IAAMG,EAASC,KAAKC,MAAML,GAC1BJ,EAAMG,EAAAA,EAAA,GAAQT,GAAqBa,EACrC,MACEP,EAAMG,EAAA,GAAQT,EAElB,CAAE,MAAAgB,GACAV,EAAMG,EAAA,GAAQT,EAChB,CAEA,OAAAS,EAAA,GAAYH,EACd,CA+CSW,GAAeT,EACxB,C,aC7HA,IAAAU,EAAAC,EAAAC,EAAA,mBAAAC,OAAAA,OAAA,GAAAC,EAAAF,EAAAG,UAAA,aAAAC,EAAAJ,EAAAK,aAAA,yBAAAC,EAAAN,EAAAE,EAAAE,EAAAE,GAAA,IAAAC,EAAAL,GAAAA,EAAAM,qBAAAC,EAAAP,EAAAO,EAAAC,EAAAC,OAAAC,OAAAL,EAAAC,WAAA,OAAAK,EAAAH,EAAA,mBAAAV,EAAAE,EAAAE,GAAA,IAAAE,EAAAC,EAAAG,EAAAI,EAAA,EAAAC,EAAAX,GAAA,GAAAY,GAAA,EAAAC,EAAA,CAAAF,EAAA,EAAAb,EAAA,EAAAgB,EAAApB,EAAAqB,EAAAC,EAAAN,EAAAM,EAAAC,KAAAvB,EAAA,GAAAsB,EAAA,SAAArB,EAAAC,GAAA,OAAAM,EAAAP,EAAAQ,EAAA,EAAAG,EAAAZ,EAAAmB,EAAAf,EAAAF,EAAAmB,CAAA,YAAAC,EAAApB,EAAAE,GAAA,IAAAK,EAAAP,EAAAU,EAAAR,EAAAH,EAAA,GAAAiB,GAAAF,IAAAV,GAAAL,EAAAgB,EAAAO,OAAAvB,IAAA,KAAAK,EAAAE,EAAAS,EAAAhB,GAAAqB,EAAAH,EAAAF,EAAAQ,EAAAjB,EAAA,GAAAN,EAAA,GAAAI,EAAAmB,IAAArB,KAAAQ,EAAAJ,GAAAC,EAAAD,EAAA,OAAAC,EAAA,MAAAD,EAAA,GAAAA,EAAA,GAAAR,GAAAQ,EAAA,IAAAc,KAAAhB,EAAAJ,EAAA,GAAAoB,EAAAd,EAAA,KAAAC,EAAA,EAAAU,EAAAC,EAAAhB,EAAAe,EAAAf,EAAAI,EAAA,IAAAc,EAAAG,IAAAnB,EAAAJ,EAAA,GAAAM,EAAA,GAAAJ,GAAAA,EAAAqB,KAAAjB,EAAA,GAAAN,EAAAM,EAAA,GAAAJ,EAAAe,EAAAf,EAAAqB,EAAAhB,EAAA,OAAAH,GAAAJ,EAAA,SAAAmB,EAAA,MAAAH,GAAA,EAAAd,CAAA,iBAAAE,EAAAW,EAAAQ,GAAA,GAAAT,EAAA,QAAAU,UAAA,oCAAAR,GAAA,IAAAD,GAAAK,EAAAL,EAAAQ,GAAAhB,EAAAQ,EAAAL,EAAAa,GAAAxB,EAAAQ,EAAA,EAAAT,EAAAY,KAAAM,GAAA,CAAAV,IAAAC,EAAAA,EAAA,GAAAA,EAAA,IAAAU,EAAAf,GAAA,GAAAkB,EAAAb,EAAAG,IAAAO,EAAAf,EAAAQ,EAAAO,EAAAC,EAAAR,GAAA,OAAAI,EAAA,EAAAR,EAAA,IAAAC,IAAAH,EAAA,QAAAL,EAAAO,EAAAF,GAAA,MAAAL,EAAAA,EAAA0B,KAAAnB,EAAAI,IAAA,MAAAc,UAAA,wCAAAzB,EAAA2B,KAAA,OAAA3B,EAAAW,EAAAX,EAAA4B,MAAApB,EAAA,IAAAA,EAAA,YAAAA,IAAAR,EAAAO,EAAAsB,SAAA7B,EAAA0B,KAAAnB,GAAAC,EAAA,IAAAG,EAAAc,UAAA,oCAAApB,EAAA,YAAAG,EAAA,GAAAD,EAAAR,CAAA,UAAAC,GAAAiB,EAAAC,EAAAf,EAAA,GAAAQ,EAAAV,EAAAyB,KAAAvB,EAAAe,MAAAE,EAAA,YAAApB,GAAAO,EAAAR,EAAAS,EAAA,EAAAG,EAAAX,CAAA,SAAAe,EAAA,UAAAa,MAAA5B,EAAA2B,KAAAV,EAAA,GAAAhB,EAAAI,EAAAE,IAAA,GAAAI,CAAA,KAAAS,EAAA,YAAAV,IAAA,UAAAoB,IAAA,UAAAC,IAAA,CAAA/B,EAAAY,OAAAoB,eAAA,IAAAxB,EAAA,GAAAL,GAAAH,EAAAA,EAAA,GAAAG,QAAAW,EAAAd,EAAA,GAAAG,EAAA,yBAAAH,GAAAW,EAAAoB,EAAAtB,UAAAC,EAAAD,UAAAG,OAAAC,OAAAL,GAAA,SAAAO,EAAAhB,GAAA,OAAAa,OAAAqB,eAAArB,OAAAqB,eAAAlC,EAAAgC,IAAAhC,EAAAmC,UAAAH,EAAAjB,EAAAf,EAAAM,EAAA,sBAAAN,EAAAU,UAAAG,OAAAC,OAAAF,GAAAZ,CAAA,QAAA+B,EAAArB,UAAAsB,EAAAjB,EAAAH,EAAA,cAAAoB,GAAAjB,EAAAiB,EAAA,cAAAD,GAAAA,EAAAK,YAAA,oBAAArB,EAAAiB,EAAA1B,EAAA,qBAAAS,EAAAH,GAAAG,EAAAH,EAAAN,EAAA,aAAAS,EAAAH,EAAAR,EAAA,yBAAAW,EAAAH,EAAA,oDAAAyB,EAAA,kBAAAC,EAAA9B,EAAA+B,EAAAvB,EAAA,cAAAD,EAAAf,EAAAE,EAAAE,EAAAH,GAAA,IAAAO,EAAAK,OAAA2B,eAAA,IAAAhC,EAAA,gBAAAR,GAAAQ,EAAA,EAAAO,EAAA,SAAAf,EAAAE,EAAAE,EAAAH,GAAA,SAAAK,EAAAJ,EAAAE,GAAAW,EAAAf,EAAAE,EAAA,SAAAF,GAAA,YAAAyC,QAAAvC,EAAAE,EAAAJ,EAAA,GAAAE,EAAAM,EAAAA,EAAAR,EAAAE,EAAA,CAAA2B,MAAAzB,EAAAsC,YAAAzC,EAAA0C,cAAA1C,EAAA2C,UAAA3C,IAAAD,EAAAE,GAAAE,GAAAE,EAAA,UAAAA,EAAA,WAAAA,EAAA,cAAAS,EAAAf,EAAAE,EAAAE,EAAAH,EAAA,UAAA4C,EAAAvC,GAAA,OAAAuC,EAAA,mBAAA1C,QAAA,iBAAAA,OAAAE,SAAA,SAAAC,GAAA,cAAAA,CAAA,WAAAA,GAAA,OAAAA,GAAA,mBAAAH,QAAAG,EAAAwC,cAAA3C,QAAAG,IAAAH,OAAAO,UAAA,gBAAAJ,CAAA,EAAAuC,EAAAvC,EAAA,UAAAyC,EAAA3C,EAAAH,EAAAD,EAAAE,EAAAI,EAAAe,EAAAZ,GAAA,QAAAD,EAAAJ,EAAAiB,GAAAZ,GAAAG,EAAAJ,EAAAqB,KAAA,OAAAzB,GAAA,YAAAJ,EAAAI,EAAA,CAAAI,EAAAoB,KAAA3B,EAAAW,GAAAoC,QAAAC,QAAArC,GAAAsC,KAAAhD,EAAAI,EAAA,UAAA6C,EAAA/C,GAAA,sBAAAH,EAAA,KAAAD,EAAAoD,UAAA,WAAAJ,QAAA,SAAA9C,EAAAI,GAAA,IAAAe,EAAAjB,EAAAiD,MAAApD,EAAAD,GAAA,SAAAsD,EAAAlD,GAAA2C,EAAA1B,EAAAnB,EAAAI,EAAAgD,EAAAC,EAAA,OAAAnD,EAAA,UAAAmD,EAAAnD,GAAA2C,EAAA1B,EAAAnB,EAAAI,EAAAgD,EAAAC,EAAA,QAAAnD,EAAA,CAAAkD,OAAA,eAAAE,EAAAvD,GAAA,IAAAC,EAAA,mBAAAuD,IAAA,IAAAA,SAAA,SAAAD,EAAA,SAAAvD,GAAA,UAAAA,IAAA,SAAAA,GAAA,eAAAyD,SAAAC,SAAAhC,KAAA1B,GAAA2D,QAAA,uBAAAxD,GAAA,yBAAAH,CAAA,EAAA4D,CAAA5D,GAAA,OAAAA,EAAA,sBAAAA,EAAA,UAAAyB,UAAA,kEAAAxB,EAAA,IAAAA,EAAA4D,IAAA7D,GAAA,OAAAC,EAAA6D,IAAA9D,GAAAC,EAAA8D,IAAA/D,EAAAgE,EAAA,UAAAA,IAAA,gBAAAhE,EAAAD,EAAAE,GAAA,GAAAgE,IAAA,OAAAC,QAAAC,UAAAf,MAAA,KAAAD,WAAA,IAAA9C,EAAA,OAAAA,EAAA+D,KAAAhB,MAAA/C,EAAAN,GAAA,IAAAiB,EAAA,IAAAhB,EAAAsB,KAAA8B,MAAApD,EAAAK,IAAA,OAAAJ,GAAAoE,EAAArD,EAAAf,EAAAQ,WAAAO,CAAA,CAAAsD,CAAAtE,EAAAmD,UAAAoB,EAAA,MAAA1B,YAAA,QAAAmB,EAAAvD,UAAAG,OAAAC,OAAAb,EAAAS,UAAA,CAAAoC,YAAA,CAAAjB,MAAAoC,EAAAvB,YAAA,EAAAE,UAAA,EAAAD,cAAA,KAAA2B,EAAAL,EAAAhE,EAAA,EAAAuD,EAAAvD,EAAA,UAAAiE,IAAA,QAAAjE,GAAAwE,QAAA/D,UAAAgE,QAAA/C,KAAAwC,QAAAC,UAAAK,QAAA,wBAAAxE,GAAA,QAAAiE,EAAA,mBAAAjE,CAAA,cAAAqE,EAAArE,EAAAD,GAAA,OAAAsE,EAAAzD,OAAAqB,eAAArB,OAAAqB,eAAAX,OAAA,SAAAtB,EAAAD,GAAA,OAAAC,EAAAkC,UAAAnC,EAAAC,CAAA,EAAAqE,EAAArE,EAAAD,EAAA,UAAAwE,EAAAvE,GAAA,OAAAuE,EAAA3D,OAAAqB,eAAArB,OAAAoB,eAAAV,OAAA,SAAAtB,GAAA,OAAAA,EAAAkC,WAAAtB,OAAAoB,eAAAhC,EAAA,EAAAuE,EAAAvE,EAAA,CA+BO,IAAK0E,EAAe,SAAfA,GAAe,OAAfA,EAAe,kCAAfA,EAAe,gCAAfA,EAAe,4BAAfA,EAAe,8BAAfA,EAAe,kBAAfA,EAAe,oCAAfA,EAAe,kBAAfA,CAAe,MAWdC,EAAW,SAAAC,GAKtB,SAAAD,EAAYE,EAAiBC,GAA+D,IAAAC,EAAxCC,EAAS7B,UAAA5B,OAAA,QAAA0D,IAAA9B,UAAA,IAAAA,UAAA,GAAU+B,EAAmB/B,UAAA5B,OAAA,EAAA4B,UAAA,QAAA8B,EAOrC,OAtDvD,SAAA7D,EAAAjB,GAAA,KAAAiB,aAAAjB,GAAA,UAAAsB,UAAA,qCA+C4F0D,CAAA,KAAAR,IACxFI,EAhDJ,SAAA/E,EAAAK,EAAAN,GAAA,OAAAM,EAAAkE,EAAAlE,GAAA,SAAAL,EAAAD,GAAA,GAAAA,IAAA,UAAA6C,EAAA7C,IAAA,mBAAAA,GAAA,OAAAA,EAAA,YAAAA,EAAA,UAAA0B,UAAA,4EAAA1B,GAAA,YAAAA,EAAA,UAAAqF,eAAA,oEAAArF,CAAA,CAAAsF,CAAArF,EAAA,CAAAsF,CAAAtF,EAAAiE,IAAAC,QAAAC,UAAA9D,EAAAN,GAAA,GAAAwE,EAAAvE,GAAA6C,aAAAxC,EAAA+C,MAAApD,EAAAD,GAAA,CAgDIwF,CAAA,KAAAZ,EAAA,CAAME,KACDW,KAAO,cACZT,EAAKD,KAAOA,EACZC,EAAKC,UAAYA,EACjBD,EAAKG,WAAaA,EAElBtE,OAAOqB,eAAc8C,EAAOJ,EAAYlE,WAAWsE,CACrD,CAAC,OAvDH,SAAA/E,EAAAD,GAAA,sBAAAA,GAAA,OAAAA,EAAA,UAAA0B,UAAA,sDAAAzB,EAAAS,UAAAG,OAAAC,OAAAd,GAAAA,EAAAU,UAAA,CAAAoC,YAAA,CAAAjB,MAAA5B,EAAA2C,UAAA,EAAAD,cAAA,KAAA9B,OAAA2B,eAAAvC,EAAA,aAAA2C,UAAA,IAAA5C,GAAAsE,EAAArE,EAAAD,EAAA,CAuDG0F,CAAAd,EAAAC,GAvDH7E,EAuDG4E,EAvDH/D,OAAA2B,eAAAxC,EAAA,aAAA4C,UAAA,IAAA5C,EAAA,IAAAA,CAuDG,CAbqB,CAarBwD,EAb8B/E,QAwDjC,SAASkH,IAEL,MAAM,IAAIf,EACR,sEACAD,EAAgBiB,gBAItB,CAeO,SAAeC,EAAYC,GAAA,OAAAC,EAAA1C,MAAC,KAADD,UAAA,CA0BlC,SAAA2C,IANC,OAMDA,EAAA5C,EAAAd,IAAAE,EA1BO,SAAAyD,EACLC,GAAc,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAzD,UAAA,OAAAf,IAAAC,EAAA,SAAAwE,GAAA,cAAAA,EAAA1G,EAgBZ,OAfFoG,EAAwBK,EAAArF,OAAA,QAAA0D,IAAA2B,EAAA,GAAAA,EAAA,GAAG,CAAC,EAEtBJ,EAASd,IACTe,EAAuD,QAA9CR,EAAgB,QAAhBC,EAAGK,EAAQI,aAAK,IAAAT,EAAAA,EAAI9G,EAAW,uBAAe,IAAA6G,EAAAA,EAhExC,yBAkEfS,EAAqC,CACzCI,YAAgC,QAArBX,EAAEI,EAAQO,mBAAW,IAAAX,EAAAA,EAlER,EAmExBY,gBAAwC,QAAzBX,EAAEG,EAAQQ,uBAAe,IAAAX,EAAAA,EAlEV,KAmE9BY,KAAkB,QAAdX,EAAEE,EAAQS,YAAI,IAAAX,EAAAA,EAlEA,IAmElBY,KAAkB,QAAdX,EAAEC,EAAQU,YAAI,IAAAX,EAAAA,EAlEA,IAqEdK,EAAyBH,EAAOU,mBAAmB,CACvDP,MAAOF,EACPC,iBAAAA,IACAG,EAAAzF,EAAA,EAEK+F,EAAiB,kBAAMC,EAAUT,EAAOX,EAAO,GAAC,EAAAD,EAAA,IACxDD,EAAA1C,MAAA,KAAAD,UAAA,UAOciE,EAASC,EAAAC,GAAA,OAAAC,EAAAnE,MAAC,KAADD,UAAA,CAoBxB,SAAAoE,IAFC,OAEDA,EAAArE,EAAAd,IAAAE,EApBA,SAAAkF,EAAyBb,EAAwBX,GAAc,IAAAyB,EAAAC,EAAAC,EAAA,OAAAvF,IAAAC,EAAA,SAAAuF,GAAA,cAAAA,EAAA5G,EAAA4G,EAAAzH,GAAA,cAAAyH,EAAA5G,EAAA,EAAA4G,EAAAzH,EAAA,EAEtC0H,EAAYlB,EAAMmB,gBAAgB9B,GA/EhC,KA+E4D,OAGvD,GAHtByB,EAAMG,EAAAzG,EAENuG,EAAWD,EAAOC,UAClBC,EAAOD,EAASC,SAEc,IAAvBA,EAAKI,OAAOxG,OAAY,CAAAqG,EAAAzH,EAAA,cAC7B,IAAIwE,EACR,4EACAD,EAAgBsD,kBACjB,cAAAJ,EAAAxG,EAAA,EAGIuG,GAAI,aAAAC,EAAA5G,EAAA,EAELiH,EAFKL,EAAAzG,GAEe,cAAAyG,EAAAxG,EAAA,KAAAoG,EAAA,kBAE7BpE,MAAA,KAAAD,UAAA,CAGD,SAAS0E,EAAeK,EAAqBC,GAC3C,OAAO,IAAIpF,QAAW,SAACC,EAASoF,GAC9B,IAAMC,EAAQC,WAAW,WACvBF,EACE,IAAIzD,EAAY,2BAAD4D,OACcJ,EAAK,IAAI,qCACpCzD,EAAgB8D,SAChB,GAGN,EAAGL,GAEHD,EACGjF,KAAK,SAACrB,GACL6G,aAAaJ,GACbrF,EAAQpB,EACV,GACC8G,MAAM,SAACC,GACNF,aAAaJ,GACbD,EAAOO,EACT,EACJ,EACF,CAEA,SAIexB,EAAgByB,GAAA,OAAAC,EAAAzF,MAAC,KAADD,UAAA,CAyB/B,SAAA0F,IAFC,OAEDA,EAAA3F,EAAAd,IAAAE,EAzBA,SAAAwG,EAAgCC,GAAyB,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAA,OAAAhH,IAAAC,EAAA,SAAAgH,GAAA,cAAAA,EAAArI,EAAAqI,EAAAlJ,GAAA,OAEnD8I,EAlIyB,IAoIpBC,EAAU,EAAC,YAAEA,GArIJ,GAqI0B,CAAAG,EAAAlJ,EAAA,eAAAkJ,EAAArI,EAAA,EAAAqI,EAAAlJ,EAAA,EAE3B4I,IAAI,cAAAM,EAAAjI,EAAA,EAAAiI,EAAAlI,GAAA,OAEuD,GAFvDkI,EAAArI,EAAA,EAAAoI,EAAAC,EAAAlI,GAEjB6H,EAAYI,aAAiBzE,EAAWyE,EAAWnB,EAAamB,IAEjDpE,WA3ID,IA2IckE,EAAuB,CAAAG,EAAAlJ,EAAA,cAC3C6I,EAAS,OAIyB,OAApCG,EAAyB,GAAhBG,KAAKC,SAAiBN,EAAKI,EAAAlJ,EAAA,EACpCqJ,EAAMP,EAAQE,GAAO,OAC3BF,GAhJuB,EAgJO,OAbYC,IAASG,EAAAlJ,EAAA,qBAkBjD6I,EAAS,cAAAK,EAAAjI,EAAA,KAAA0H,EAAA,kBAChB1F,MAAA,KAAAD,UAAA,CAGD,SAAS8E,EAAcwB,GAErB,GAAIA,aAAiB9E,EACnB,OAAO8E,EAGT,IAAM5E,EAAU4E,aAAiBjL,MAAQiL,EAAM5E,QAAU6E,OAAOD,GAC1DvE,EA4ER,SAA2BuE,GACzB,GAAIA,GAA0B,WAAjB7G,EAAO6G,GAAoB,CACtC,IAAME,EAAMF,EACZ,GAA0B,iBAAfE,EAAIC,OAAqB,OAAOD,EAAIC,OAC/C,GAA8B,iBAAnBD,EAAIzE,WAAyB,OAAOyE,EAAIzE,WACnD,GAAwB,iBAAbyE,EAAI7E,KAAmB,OAAO6E,EAAI7E,KAE7C,GAAI6E,EAAIjC,UAAoC,WAAxB9E,EAAO+G,EAAIjC,UAAuB,CACpD,IAAMmC,EAAOF,EAAIjC,SACjB,GAA2B,iBAAhBmC,EAAKD,OAAqB,OAAOC,EAAKD,MACnD,CACF,CAEF,CAzFqBE,CAAkBL,GAGrC,OAAmB,MAAfvE,GAAqC,MAAfA,GAAsB,YAAY6E,KAAKlF,GACxD,IAAIF,EACT,gEACAD,EAAgBiB,iBAChB,EACAT,GAKe,MAAfA,GAAsB,eAAe6E,KAAKlF,IAAY,qBAAqBkF,KAAKlF,GAC3E,IAAIF,EACT,yDACAD,EAAgBsF,cAChB,EACA,KAKe,MAAf9E,GAAsB,SAAS6E,KAAKlF,GAC/B,IAAIF,EACT,yFACAD,EAAgBuF,gBAChB,EACA,KAMF,WAAWF,KAAKlF,IAChB,gBAAgBkF,KAAKlF,IACrB,gBAAgBkF,KAAKlF,IACrB,aAAakF,KAAKlF,IAClB,WAAWkF,KAAKlF,GAET,IAAIF,EACT,yDACAD,EAAgBwF,eAChB,GAKA,UAAUH,KAAKlF,IAAY,WAAWkF,KAAKlF,IAAY,UAAUkF,KAAKlF,GACjE,IAAIF,EACT,sDACAD,EAAgBsD,kBAChB,GAKA9C,GAAcA,GAAc,IACvB,IAAIP,EAAY,iBAAD4D,OACHrD,EAAU,gBAC3BR,EAAgByF,SAChB,EACAjF,GAKG,IAAIP,EAAY,qBAAD4D,OACC1D,GACrBH,EAAgByF,SAChB,EACAjF,EAEJ,CAmBA,SAASsE,EAAMrB,GACb,OAAO,IAAIpF,QAAQ,SAACC,GAAO,OAAKsF,WAAWtF,EAASmF,EAAG,EACzD,C,ggCChRO,SAASiC,EAAYC,EAAkBC,GAC5C,IAAKD,EACH,MAAM,IAAI7L,MAAM,oCAKlB,IAFA,IAAIiJ,EAAS4C,EAEbE,EAAA,EAAAC,EAA2B5J,OAAO6J,QAAQH,GAAUC,EAAAC,EAAAjJ,OAAAgJ,IAAE,CAAjD,IAAAG,EAAAC,EAAAH,EAAAD,GAAA,GAAOlL,EAAGqL,EAAA,GAAE9I,EAAK8I,EAAA,GAEdE,EAAc,KAAHrC,OAAQlJ,EAAG,MAC5BoI,EAASA,EAAOoD,MAAMD,GAAaE,KAAKlJ,EAC1C,CAEA,OAAO6F,CACT,C,aClEA,IAAA1H,EAAAC,EAAAC,EAAA,mBAAAC,OAAAA,OAAA,GAAAC,EAAAF,EAAAG,UAAA,aAAAC,EAAAJ,EAAAK,aAAA,yBAAAC,EAAAN,EAAAE,EAAAE,EAAAE,GAAA,IAAAC,EAAAL,GAAAA,EAAAM,qBAAAC,EAAAP,EAAAO,EAAAC,EAAAC,OAAAC,OAAAL,EAAAC,WAAA,OAAAK,EAAAH,EAAA,mBAAAV,EAAAE,EAAAE,GAAA,IAAAE,EAAAC,EAAAG,EAAAI,EAAA,EAAAC,EAAAX,GAAA,GAAAY,GAAA,EAAAC,EAAA,CAAAF,EAAA,EAAAb,EAAA,EAAAgB,EAAApB,EAAAqB,EAAAC,EAAAN,EAAAM,EAAAC,KAAAvB,EAAA,GAAAsB,EAAA,SAAArB,EAAAC,GAAA,OAAAM,EAAAP,EAAAQ,EAAA,EAAAG,EAAAZ,EAAAmB,EAAAf,EAAAF,EAAAmB,CAAA,YAAAC,EAAApB,EAAAE,GAAA,IAAAK,EAAAP,EAAAU,EAAAR,EAAAH,EAAA,GAAAiB,GAAAF,IAAAV,GAAAL,EAAAgB,EAAAO,OAAAvB,IAAA,KAAAK,EAAAE,EAAAS,EAAAhB,GAAAqB,EAAAH,EAAAF,EAAAQ,EAAAjB,EAAA,GAAAN,EAAA,GAAAI,EAAAmB,IAAArB,KAAAQ,EAAAJ,GAAAC,EAAAD,EAAA,OAAAC,EAAA,MAAAD,EAAA,GAAAA,EAAA,GAAAR,GAAAQ,EAAA,IAAAc,KAAAhB,EAAAJ,EAAA,GAAAoB,EAAAd,EAAA,KAAAC,EAAA,EAAAU,EAAAC,EAAAhB,EAAAe,EAAAf,EAAAI,EAAA,IAAAc,EAAAG,IAAAnB,EAAAJ,EAAA,GAAAM,EAAA,GAAAJ,GAAAA,EAAAqB,KAAAjB,EAAA,GAAAN,EAAAM,EAAA,GAAAJ,EAAAe,EAAAf,EAAAqB,EAAAhB,EAAA,OAAAH,GAAAJ,EAAA,SAAAmB,EAAA,MAAAH,GAAA,EAAAd,CAAA,iBAAAE,EAAAW,EAAAQ,GAAA,GAAAT,EAAA,QAAAU,UAAA,oCAAAR,GAAA,IAAAD,GAAAK,EAAAL,EAAAQ,GAAAhB,EAAAQ,EAAAL,EAAAa,GAAAxB,EAAAQ,EAAA,EAAAT,EAAAY,KAAAM,GAAA,CAAAV,IAAAC,EAAAA,EAAA,GAAAA,EAAA,IAAAU,EAAAf,GAAA,GAAAkB,EAAAb,EAAAG,IAAAO,EAAAf,EAAAQ,EAAAO,EAAAC,EAAAR,GAAA,OAAAI,EAAA,EAAAR,EAAA,IAAAC,IAAAH,EAAA,QAAAL,EAAAO,EAAAF,GAAA,MAAAL,EAAAA,EAAA0B,KAAAnB,EAAAI,IAAA,MAAAc,UAAA,wCAAAzB,EAAA2B,KAAA,OAAA3B,EAAAW,EAAAX,EAAA4B,MAAApB,EAAA,IAAAA,EAAA,YAAAA,IAAAR,EAAAO,EAAAsB,SAAA7B,EAAA0B,KAAAnB,GAAAC,EAAA,IAAAG,EAAAc,UAAA,oCAAApB,EAAA,YAAAG,EAAA,GAAAD,EAAAR,CAAA,UAAAC,GAAAiB,EAAAC,EAAAf,EAAA,GAAAQ,EAAAV,EAAAyB,KAAAvB,EAAAe,MAAAE,EAAA,YAAApB,GAAAO,EAAAR,EAAAS,EAAA,EAAAG,EAAAX,CAAA,SAAAe,EAAA,UAAAa,MAAA5B,EAAA2B,KAAAV,EAAA,GAAAhB,EAAAI,EAAAE,IAAA,GAAAI,CAAA,KAAAS,EAAA,YAAAV,IAAA,UAAAoB,IAAA,UAAAC,IAAA,CAAA/B,EAAAY,OAAAoB,eAAA,IAAAxB,EAAA,GAAAL,GAAAH,EAAAA,EAAA,GAAAG,QAAAW,EAAAd,EAAA,GAAAG,EAAA,yBAAAH,GAAAW,EAAAoB,EAAAtB,UAAAC,EAAAD,UAAAG,OAAAC,OAAAL,GAAA,SAAAO,EAAAhB,GAAA,OAAAa,OAAAqB,eAAArB,OAAAqB,eAAAlC,EAAAgC,IAAAhC,EAAAmC,UAAAH,EAAAjB,EAAAf,EAAAM,EAAA,sBAAAN,EAAAU,UAAAG,OAAAC,OAAAF,GAAAZ,CAAA,QAAA+B,EAAArB,UAAAsB,EAAAjB,EAAAH,EAAA,cAAAoB,GAAAjB,EAAAiB,EAAA,cAAAD,GAAAA,EAAAK,YAAA,oBAAArB,EAAAiB,EAAA1B,EAAA,qBAAAS,EAAAH,GAAAG,EAAAH,EAAAN,EAAA,aAAAS,EAAAH,EAAAR,EAAA,yBAAAW,EAAAH,EAAA,oDAAAyB,EAAA,kBAAAC,EAAA9B,EAAA+B,EAAAvB,EAAA,cAAAD,EAAAf,EAAAE,EAAAE,EAAAH,GAAA,IAAAO,EAAAK,OAAA2B,eAAA,IAAAhC,EAAA,gBAAAR,GAAAQ,EAAA,EAAAO,EAAA,SAAAf,EAAAE,EAAAE,EAAAH,GAAA,SAAAK,EAAAJ,EAAAE,GAAAW,EAAAf,EAAAE,EAAA,SAAAF,GAAA,YAAAyC,QAAAvC,EAAAE,EAAAJ,EAAA,GAAAE,EAAAM,EAAAA,EAAAR,EAAAE,EAAA,CAAA2B,MAAAzB,EAAAsC,YAAAzC,EAAA0C,cAAA1C,EAAA2C,UAAA3C,IAAAD,EAAAE,GAAAE,GAAAE,EAAA,UAAAA,EAAA,WAAAA,EAAA,cAAAS,EAAAf,EAAAE,EAAAE,EAAAH,EAAA,UAAA8C,EAAA3C,EAAAH,EAAAD,EAAAE,EAAAI,EAAAe,EAAAZ,GAAA,QAAAD,EAAAJ,EAAAiB,GAAAZ,GAAAG,EAAAJ,EAAAqB,KAAA,OAAAzB,GAAA,YAAAJ,EAAAI,EAAA,CAAAI,EAAAoB,KAAA3B,EAAAW,GAAAoC,QAAAC,QAAArC,GAAAsC,KAAAhD,EAAAI,EAAA,CA4BA,IAAM0K,EAAiD,CACrDC,YAAa,gDACbC,gBAAiB,kCACjBC,aAAc,wDACdC,kBAAmB,gDAOrB,SAIeC,EAAmBvF,EAAAwB,GAAA,OAAAgE,EAAAjI,MAAC,KAADD,UAAA,CA4ClC,SAAAkI,IAvFA,IAAAlL,EAmFC,OAnFDA,EAuFAiC,IAAAE,EA5CA,SAAAyD,EACEuF,EACAC,GAAiC,IAAAC,EAAAC,EAAAzF,EAAA0F,EAAA7G,EAAA8G,EAAA,OAAAvJ,IAAAC,EAAA,SAAAwE,GAAA,cAAAA,EAAA7F,EAAA6F,EAAA1G,GAAA,OAEO,GAAlCqL,EAAOI,OAAOC,QAAQC,QAAQN,KAEzB,CAAF3E,EAAA1G,EAAA,QACsC,OAA7C4L,EAAiB,oBAAqBR,GAAO1E,EAAAzF,EAAA,iBAAAyF,EAAA7F,EAAA,EAAA6F,EAAA1G,EAAA,EAMlB6L,EAAgBR,GAAK,OAA9B,IAAZC,EAAY5E,EAAA1F,GAEA4G,OAAQ,CAAFlB,EAAA1G,EAAA,QACoC,OAA1D4L,EAAiB,iCAAkCR,GAAO1E,EAAAzF,EAAA,UAS1D,OAHI4E,EAASoE,EC2BmB,uZD3BiB,CACjD6B,KAAMR,EACNS,kBAHiBnB,EAAaO,KAI9BzE,EAAA1G,EAAA,EAEqByF,EAAaI,EAAQ,CAC1Cc,YAAa,GACbC,gBAAiB,OACjB,OAHY,OAAR2E,EAAQ7E,EAAA1F,EAAA0F,EAAA1G,EAAG,EAMXgM,EAAgBX,EAAME,GAAS,OAErCK,EAAiB,kBAAmBR,GAAO1E,EAAA1G,EAAA,eAAA0G,EAAA7F,EAAA,EAAA2K,EAAA9E,EAAA1F,EAErC0D,GAAU8G,aAAA,EAAAA,EAAK9G,UAAW,0BAChCkH,EAAiB,UAADxD,OAAW1D,GAAW0G,GAAO,cAAA1E,EAAAzF,EAAA,KAAA2E,EAAA,gBAMjDsF,EAvFA,eAAArL,EAAA,KAAAD,EAAAoD,UAAA,WAAAJ,QAAA,SAAA9C,EAAAI,GAAA,IAAAe,EAAAjB,EAAAiD,MAAApD,EAAAD,GAAA,SAAAsD,EAAAlD,GAAA2C,EAAA1B,EAAAnB,EAAAI,EAAAgD,EAAAC,EAAA,OAAAnD,EAAA,UAAAmD,EAAAnD,GAAA2C,EAAA1B,EAAAnB,EAAAI,EAAAgD,EAAAC,EAAA,QAAAnD,EAAA,CAAAkD,OAAA,MAmFCgI,EAAAjI,MAAA,KAAAD,UAAA,CAMD,SAAS6I,EAAgBR,GACvB,OAAO,IAAIzI,QAAQ,SAACC,EAASoF,GACc,mBAA9BoD,EAAKY,qBAKhBZ,EAAKY,qBACHR,OAAOS,aAAaC,KACpB,SAAC7E,GAC2D,IAAA8E,EAEnDC,EAFH/E,EAAOmC,SAAWgC,OAAOa,kBAAkBC,UAC7C1J,GAAoB,QAAZuJ,EAAA9E,EAAO7F,aAAK,IAAA2K,OAAA,EAAZA,EAAcI,OAAQ,IAE9BvE,EAAO,IAAI5J,OAAkB,QAAZgO,EAAA/E,EAAOgC,aAAK,IAAA+C,OAAA,EAAZA,EAAc3H,UAAW,gCAE9C,GAZAuD,EAAO,IAAI5J,MAAM,gEAcrB,EACF,CAEA,SAAS2N,EAAgBX,EAAW7D,GAClC,OAAO,IAAI5E,QAAQ,SAACC,EAASoF,GACtBoD,EAAKoB,MAAkD,mBAAnCpB,EAAKoB,KAAKC,qBAKnCrB,EAAKoB,KAAKC,qBACRlF,EACA,CAAEmF,aAAclB,OAAOS,aAAaC,MACpC,SAAC7E,GAGQ,IAAAsF,EAFHtF,EAAOmC,SAAWgC,OAAOa,kBAAkBC,UAC7C1J,IAEAoF,EAAO,IAAI5J,OAAkB,QAAZuO,EAAAtF,EAAOgC,aAAK,IAAAsD,OAAA,EAAZA,EAAclI,UAAW,0BAE9C,GAbAuD,EAAO,IAAI5J,MAAM,iCAerB,EACF,CAEA,SAASuN,EAAiBlH,EAAiB0G,GACzC,IAAMC,EAAOI,OAAOC,QAAQC,QAAQN,KAEhCA,GACFA,EAAKwB,qBAAqBC,aAAa,oBAAqB,CAC1DC,KAAMtB,OAAOuB,aAAaC,4BAA4BC,qBACtDxI,QAAAA,EACAyI,KAAM,aACNC,YAAY,IAIhBhC,EAAMiC,WACR,CAMA,SAASC,EAAWlC,GAClBH,EAAoB,cAAeG,EACrC,CAEA,SAASmC,EAAenC,GACtBH,EAAoB,kBAAmBG,EACzC,CAEA,SAASoC,GAAYpC,GACnBH,EAAoB,eAAgBG,EACtC,CAEA,SAASqC,GAAiBrC,GACxBH,EAAoB,oBAAqBG,EAC3C,CAMAK,OAAOiC,QAAQ,WAEbjC,OAAOkC,QAAQC,UAAU,aAAcN,GACvC7B,OAAOkC,QAAQC,UAAU,iBAAkBL,GAC3C9B,OAAOkC,QAAQC,UAAU,cAAeJ,IACxC/B,OAAOkC,QAAQC,UAAU,mBAAoBH,GAC/C,E","sources":["webpack://Glide/./node_modules/@google/generative-ai/dist/index.mjs","webpack://Glide/./src/features/settings.ts","webpack://Glide/./src/services/gemini.ts","webpack://Glide/./src/prompts/builder.ts","webpack://Glide/./src/commands/commands.ts","webpack://Glide/./src/prompts/templates.ts"],"sourcesContent":["/**\n * Contains the list of OpenAPI data types\n * as defined by https://swagger.io/docs/specification/data-models/data-types/\n * @public\n */\nvar SchemaType;\n(function (SchemaType) {\n    /** String type. */\n    SchemaType[\"STRING\"] = \"string\";\n    /** Number type. */\n    SchemaType[\"NUMBER\"] = \"number\";\n    /** Integer type. */\n    SchemaType[\"INTEGER\"] = \"integer\";\n    /** Boolean type. */\n    SchemaType[\"BOOLEAN\"] = \"boolean\";\n    /** Array type. */\n    SchemaType[\"ARRAY\"] = \"array\";\n    /** Object type. */\n    SchemaType[\"OBJECT\"] = \"object\";\n})(SchemaType || (SchemaType = {}));\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * @public\n */\nvar ExecutableCodeLanguage;\n(function (ExecutableCodeLanguage) {\n    ExecutableCodeLanguage[\"LANGUAGE_UNSPECIFIED\"] = \"language_unspecified\";\n    ExecutableCodeLanguage[\"PYTHON\"] = \"python\";\n})(ExecutableCodeLanguage || (ExecutableCodeLanguage = {}));\n/**\n * Possible outcomes of code execution.\n * @public\n */\nvar Outcome;\n(function (Outcome) {\n    /**\n     * Unspecified status. This value should not be used.\n     */\n    Outcome[\"OUTCOME_UNSPECIFIED\"] = \"outcome_unspecified\";\n    /**\n     * Code execution completed successfully.\n     */\n    Outcome[\"OUTCOME_OK\"] = \"outcome_ok\";\n    /**\n     * Code execution finished but with a failure. `stderr` should contain the\n     * reason.\n     */\n    Outcome[\"OUTCOME_FAILED\"] = \"outcome_failed\";\n    /**\n     * Code execution ran for too long, and was cancelled. There may or may not\n     * be a partial output present.\n     */\n    Outcome[\"OUTCOME_DEADLINE_EXCEEDED\"] = \"outcome_deadline_exceeded\";\n})(Outcome || (Outcome = {}));\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Possible roles.\n * @public\n */\nconst POSSIBLE_ROLES = [\"user\", \"model\", \"function\", \"system\"];\n/**\n * Harm categories that would cause prompts or candidates to be blocked.\n * @public\n */\nvar HarmCategory;\n(function (HarmCategory) {\n    HarmCategory[\"HARM_CATEGORY_UNSPECIFIED\"] = \"HARM_CATEGORY_UNSPECIFIED\";\n    HarmCategory[\"HARM_CATEGORY_HATE_SPEECH\"] = \"HARM_CATEGORY_HATE_SPEECH\";\n    HarmCategory[\"HARM_CATEGORY_SEXUALLY_EXPLICIT\"] = \"HARM_CATEGORY_SEXUALLY_EXPLICIT\";\n    HarmCategory[\"HARM_CATEGORY_HARASSMENT\"] = \"HARM_CATEGORY_HARASSMENT\";\n    HarmCategory[\"HARM_CATEGORY_DANGEROUS_CONTENT\"] = \"HARM_CATEGORY_DANGEROUS_CONTENT\";\n    HarmCategory[\"HARM_CATEGORY_CIVIC_INTEGRITY\"] = \"HARM_CATEGORY_CIVIC_INTEGRITY\";\n})(HarmCategory || (HarmCategory = {}));\n/**\n * Threshold above which a prompt or candidate will be blocked.\n * @public\n */\nvar HarmBlockThreshold;\n(function (HarmBlockThreshold) {\n    /** Threshold is unspecified. */\n    HarmBlockThreshold[\"HARM_BLOCK_THRESHOLD_UNSPECIFIED\"] = \"HARM_BLOCK_THRESHOLD_UNSPECIFIED\";\n    /** Content with NEGLIGIBLE will be allowed. */\n    HarmBlockThreshold[\"BLOCK_LOW_AND_ABOVE\"] = \"BLOCK_LOW_AND_ABOVE\";\n    /** Content with NEGLIGIBLE and LOW will be allowed. */\n    HarmBlockThreshold[\"BLOCK_MEDIUM_AND_ABOVE\"] = \"BLOCK_MEDIUM_AND_ABOVE\";\n    /** Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed. */\n    HarmBlockThreshold[\"BLOCK_ONLY_HIGH\"] = \"BLOCK_ONLY_HIGH\";\n    /** All content will be allowed. */\n    HarmBlockThreshold[\"BLOCK_NONE\"] = \"BLOCK_NONE\";\n})(HarmBlockThreshold || (HarmBlockThreshold = {}));\n/**\n * Probability that a prompt or candidate matches a harm category.\n * @public\n */\nvar HarmProbability;\n(function (HarmProbability) {\n    /** Probability is unspecified. */\n    HarmProbability[\"HARM_PROBABILITY_UNSPECIFIED\"] = \"HARM_PROBABILITY_UNSPECIFIED\";\n    /** Content has a negligible chance of being unsafe. */\n    HarmProbability[\"NEGLIGIBLE\"] = \"NEGLIGIBLE\";\n    /** Content has a low chance of being unsafe. */\n    HarmProbability[\"LOW\"] = \"LOW\";\n    /** Content has a medium chance of being unsafe. */\n    HarmProbability[\"MEDIUM\"] = \"MEDIUM\";\n    /** Content has a high chance of being unsafe. */\n    HarmProbability[\"HIGH\"] = \"HIGH\";\n})(HarmProbability || (HarmProbability = {}));\n/**\n * Reason that a prompt was blocked.\n * @public\n */\nvar BlockReason;\n(function (BlockReason) {\n    // A blocked reason was not specified.\n    BlockReason[\"BLOCKED_REASON_UNSPECIFIED\"] = \"BLOCKED_REASON_UNSPECIFIED\";\n    // Content was blocked by safety settings.\n    BlockReason[\"SAFETY\"] = \"SAFETY\";\n    // Content was blocked, but the reason is uncategorized.\n    BlockReason[\"OTHER\"] = \"OTHER\";\n})(BlockReason || (BlockReason = {}));\n/**\n * Reason that a candidate finished.\n * @public\n */\nvar FinishReason;\n(function (FinishReason) {\n    // Default value. This value is unused.\n    FinishReason[\"FINISH_REASON_UNSPECIFIED\"] = \"FINISH_REASON_UNSPECIFIED\";\n    // Natural stop point of the model or provided stop sequence.\n    FinishReason[\"STOP\"] = \"STOP\";\n    // The maximum number of tokens as specified in the request was reached.\n    FinishReason[\"MAX_TOKENS\"] = \"MAX_TOKENS\";\n    // The candidate content was flagged for safety reasons.\n    FinishReason[\"SAFETY\"] = \"SAFETY\";\n    // The candidate content was flagged for recitation reasons.\n    FinishReason[\"RECITATION\"] = \"RECITATION\";\n    // The candidate content was flagged for using an unsupported language.\n    FinishReason[\"LANGUAGE\"] = \"LANGUAGE\";\n    // Token generation stopped because the content contains forbidden terms.\n    FinishReason[\"BLOCKLIST\"] = \"BLOCKLIST\";\n    // Token generation stopped for potentially containing prohibited content.\n    FinishReason[\"PROHIBITED_CONTENT\"] = \"PROHIBITED_CONTENT\";\n    // Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).\n    FinishReason[\"SPII\"] = \"SPII\";\n    // The function call generated by the model is invalid.\n    FinishReason[\"MALFORMED_FUNCTION_CALL\"] = \"MALFORMED_FUNCTION_CALL\";\n    // Unknown reason.\n    FinishReason[\"OTHER\"] = \"OTHER\";\n})(FinishReason || (FinishReason = {}));\n/**\n * Task type for embedding content.\n * @public\n */\nvar TaskType;\n(function (TaskType) {\n    TaskType[\"TASK_TYPE_UNSPECIFIED\"] = \"TASK_TYPE_UNSPECIFIED\";\n    TaskType[\"RETRIEVAL_QUERY\"] = \"RETRIEVAL_QUERY\";\n    TaskType[\"RETRIEVAL_DOCUMENT\"] = \"RETRIEVAL_DOCUMENT\";\n    TaskType[\"SEMANTIC_SIMILARITY\"] = \"SEMANTIC_SIMILARITY\";\n    TaskType[\"CLASSIFICATION\"] = \"CLASSIFICATION\";\n    TaskType[\"CLUSTERING\"] = \"CLUSTERING\";\n})(TaskType || (TaskType = {}));\n/**\n * @public\n */\nvar FunctionCallingMode;\n(function (FunctionCallingMode) {\n    // Unspecified function calling mode. This value should not be used.\n    FunctionCallingMode[\"MODE_UNSPECIFIED\"] = \"MODE_UNSPECIFIED\";\n    // Default model behavior, model decides to predict either a function call\n    // or a natural language repspose.\n    FunctionCallingMode[\"AUTO\"] = \"AUTO\";\n    // Model is constrained to always predicting a function call only.\n    // If \"allowed_function_names\" are set, the predicted function call will be\n    // limited to any one of \"allowed_function_names\", else the predicted\n    // function call will be any one of the provided \"function_declarations\".\n    FunctionCallingMode[\"ANY\"] = \"ANY\";\n    // Model will not predict any function call. Model behavior is same as when\n    // not passing any function declarations.\n    FunctionCallingMode[\"NONE\"] = \"NONE\";\n})(FunctionCallingMode || (FunctionCallingMode = {}));\n/**\n * The mode of the predictor to be used in dynamic retrieval.\n * @public\n */\nvar DynamicRetrievalMode;\n(function (DynamicRetrievalMode) {\n    // Unspecified function calling mode. This value should not be used.\n    DynamicRetrievalMode[\"MODE_UNSPECIFIED\"] = \"MODE_UNSPECIFIED\";\n    // Run retrieval only when system decides it is necessary.\n    DynamicRetrievalMode[\"MODE_DYNAMIC\"] = \"MODE_DYNAMIC\";\n})(DynamicRetrievalMode || (DynamicRetrievalMode = {}));\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Basic error type for this SDK.\n * @public\n */\nclass GoogleGenerativeAIError extends Error {\n    constructor(message) {\n        super(`[GoogleGenerativeAI Error]: ${message}`);\n    }\n}\n/**\n * Errors in the contents of a response from the model. This includes parsing\n * errors, or responses including a safety block reason.\n * @public\n */\nclass GoogleGenerativeAIResponseError extends GoogleGenerativeAIError {\n    constructor(message, response) {\n        super(message);\n        this.response = response;\n    }\n}\n/**\n * Error class covering HTTP errors when calling the server. Includes HTTP\n * status, statusText, and optional details, if provided in the server response.\n * @public\n */\nclass GoogleGenerativeAIFetchError extends GoogleGenerativeAIError {\n    constructor(message, status, statusText, errorDetails) {\n        super(message);\n        this.status = status;\n        this.statusText = statusText;\n        this.errorDetails = errorDetails;\n    }\n}\n/**\n * Errors in the contents of a request originating from user input.\n * @public\n */\nclass GoogleGenerativeAIRequestInputError extends GoogleGenerativeAIError {\n}\n/**\n * Error thrown when a request is aborted, either due to a timeout or\n * intentional cancellation by the user.\n * @public\n */\nclass GoogleGenerativeAIAbortError extends GoogleGenerativeAIError {\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst DEFAULT_BASE_URL = \"https://generativelanguage.googleapis.com\";\nconst DEFAULT_API_VERSION = \"v1beta\";\n/**\n * We can't `require` package.json if this runs on web. We will use rollup to\n * swap in the version number here at build time.\n */\nconst PACKAGE_VERSION = \"0.24.1\";\nconst PACKAGE_LOG_HEADER = \"genai-js\";\nvar Task;\n(function (Task) {\n    Task[\"GENERATE_CONTENT\"] = \"generateContent\";\n    Task[\"STREAM_GENERATE_CONTENT\"] = \"streamGenerateContent\";\n    Task[\"COUNT_TOKENS\"] = \"countTokens\";\n    Task[\"EMBED_CONTENT\"] = \"embedContent\";\n    Task[\"BATCH_EMBED_CONTENTS\"] = \"batchEmbedContents\";\n})(Task || (Task = {}));\nclass RequestUrl {\n    constructor(model, task, apiKey, stream, requestOptions) {\n        this.model = model;\n        this.task = task;\n        this.apiKey = apiKey;\n        this.stream = stream;\n        this.requestOptions = requestOptions;\n    }\n    toString() {\n        var _a, _b;\n        const apiVersion = ((_a = this.requestOptions) === null || _a === void 0 ? void 0 : _a.apiVersion) || DEFAULT_API_VERSION;\n        const baseUrl = ((_b = this.requestOptions) === null || _b === void 0 ? void 0 : _b.baseUrl) || DEFAULT_BASE_URL;\n        let url = `${baseUrl}/${apiVersion}/${this.model}:${this.task}`;\n        if (this.stream) {\n            url += \"?alt=sse\";\n        }\n        return url;\n    }\n}\n/**\n * Simple, but may become more complex if we add more versions to log.\n */\nfunction getClientHeaders(requestOptions) {\n    const clientHeaders = [];\n    if (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient) {\n        clientHeaders.push(requestOptions.apiClient);\n    }\n    clientHeaders.push(`${PACKAGE_LOG_HEADER}/${PACKAGE_VERSION}`);\n    return clientHeaders.join(\" \");\n}\nasync function getHeaders(url) {\n    var _a;\n    const headers = new Headers();\n    headers.append(\"Content-Type\", \"application/json\");\n    headers.append(\"x-goog-api-client\", getClientHeaders(url.requestOptions));\n    headers.append(\"x-goog-api-key\", url.apiKey);\n    let customHeaders = (_a = url.requestOptions) === null || _a === void 0 ? void 0 : _a.customHeaders;\n    if (customHeaders) {\n        if (!(customHeaders instanceof Headers)) {\n            try {\n                customHeaders = new Headers(customHeaders);\n            }\n            catch (e) {\n                throw new GoogleGenerativeAIRequestInputError(`unable to convert customHeaders value ${JSON.stringify(customHeaders)} to Headers: ${e.message}`);\n            }\n        }\n        for (const [headerName, headerValue] of customHeaders.entries()) {\n            if (headerName === \"x-goog-api-key\") {\n                throw new GoogleGenerativeAIRequestInputError(`Cannot set reserved header name ${headerName}`);\n            }\n            else if (headerName === \"x-goog-api-client\") {\n                throw new GoogleGenerativeAIRequestInputError(`Header name ${headerName} can only be set using the apiClient field`);\n            }\n            headers.append(headerName, headerValue);\n        }\n    }\n    return headers;\n}\nasync function constructModelRequest(model, task, apiKey, stream, body, requestOptions) {\n    const url = new RequestUrl(model, task, apiKey, stream, requestOptions);\n    return {\n        url: url.toString(),\n        fetchOptions: Object.assign(Object.assign({}, buildFetchOptions(requestOptions)), { method: \"POST\", headers: await getHeaders(url), body }),\n    };\n}\nasync function makeModelRequest(model, task, apiKey, stream, body, requestOptions = {}, \n// Allows this to be stubbed for tests\nfetchFn = fetch) {\n    const { url, fetchOptions } = await constructModelRequest(model, task, apiKey, stream, body, requestOptions);\n    return makeRequest(url, fetchOptions, fetchFn);\n}\nasync function makeRequest(url, fetchOptions, fetchFn = fetch) {\n    let response;\n    try {\n        response = await fetchFn(url, fetchOptions);\n    }\n    catch (e) {\n        handleResponseError(e, url);\n    }\n    if (!response.ok) {\n        await handleResponseNotOk(response, url);\n    }\n    return response;\n}\nfunction handleResponseError(e, url) {\n    let err = e;\n    if (err.name === \"AbortError\") {\n        err = new GoogleGenerativeAIAbortError(`Request aborted when fetching ${url.toString()}: ${e.message}`);\n        err.stack = e.stack;\n    }\n    else if (!(e instanceof GoogleGenerativeAIFetchError ||\n        e instanceof GoogleGenerativeAIRequestInputError)) {\n        err = new GoogleGenerativeAIError(`Error fetching from ${url.toString()}: ${e.message}`);\n        err.stack = e.stack;\n    }\n    throw err;\n}\nasync function handleResponseNotOk(response, url) {\n    let message = \"\";\n    let errorDetails;\n    try {\n        const json = await response.json();\n        message = json.error.message;\n        if (json.error.details) {\n            message += ` ${JSON.stringify(json.error.details)}`;\n            errorDetails = json.error.details;\n        }\n    }\n    catch (e) {\n        // ignored\n    }\n    throw new GoogleGenerativeAIFetchError(`Error fetching from ${url.toString()}: [${response.status} ${response.statusText}] ${message}`, response.status, response.statusText, errorDetails);\n}\n/**\n * Generates the request options to be passed to the fetch API.\n * @param requestOptions - The user-defined request options.\n * @returns The generated request options.\n */\nfunction buildFetchOptions(requestOptions) {\n    const fetchOptions = {};\n    if ((requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.signal) !== undefined || (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeout) >= 0) {\n        const controller = new AbortController();\n        if ((requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeout) >= 0) {\n            setTimeout(() => controller.abort(), requestOptions.timeout);\n        }\n        if (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.signal) {\n            requestOptions.signal.addEventListener(\"abort\", () => {\n                controller.abort();\n            });\n        }\n        fetchOptions.signal = controller.signal;\n    }\n    return fetchOptions;\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Adds convenience helper methods to a response object, including stream\n * chunks (as long as each chunk is a complete GenerateContentResponse JSON).\n */\nfunction addHelpers(response) {\n    response.text = () => {\n        if (response.candidates && response.candidates.length > 0) {\n            if (response.candidates.length > 1) {\n                console.warn(`This response had ${response.candidates.length} ` +\n                    `candidates. Returning text from the first candidate only. ` +\n                    `Access response.candidates directly to use the other candidates.`);\n            }\n            if (hadBadFinishReason(response.candidates[0])) {\n                throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);\n            }\n            return getText(response);\n        }\n        else if (response.promptFeedback) {\n            throw new GoogleGenerativeAIResponseError(`Text not available. ${formatBlockErrorMessage(response)}`, response);\n        }\n        return \"\";\n    };\n    /**\n     * TODO: remove at next major version\n     */\n    response.functionCall = () => {\n        if (response.candidates && response.candidates.length > 0) {\n            if (response.candidates.length > 1) {\n                console.warn(`This response had ${response.candidates.length} ` +\n                    `candidates. Returning function calls from the first candidate only. ` +\n                    `Access response.candidates directly to use the other candidates.`);\n            }\n            if (hadBadFinishReason(response.candidates[0])) {\n                throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);\n            }\n            console.warn(`response.functionCall() is deprecated. ` +\n                `Use response.functionCalls() instead.`);\n            return getFunctionCalls(response)[0];\n        }\n        else if (response.promptFeedback) {\n            throw new GoogleGenerativeAIResponseError(`Function call not available. ${formatBlockErrorMessage(response)}`, response);\n        }\n        return undefined;\n    };\n    response.functionCalls = () => {\n        if (response.candidates && response.candidates.length > 0) {\n            if (response.candidates.length > 1) {\n                console.warn(`This response had ${response.candidates.length} ` +\n                    `candidates. Returning function calls from the first candidate only. ` +\n                    `Access response.candidates directly to use the other candidates.`);\n            }\n            if (hadBadFinishReason(response.candidates[0])) {\n                throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);\n            }\n            return getFunctionCalls(response);\n        }\n        else if (response.promptFeedback) {\n            throw new GoogleGenerativeAIResponseError(`Function call not available. ${formatBlockErrorMessage(response)}`, response);\n        }\n        return undefined;\n    };\n    return response;\n}\n/**\n * Returns all text found in all parts of first candidate.\n */\nfunction getText(response) {\n    var _a, _b, _c, _d;\n    const textStrings = [];\n    if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {\n        for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {\n            if (part.text) {\n                textStrings.push(part.text);\n            }\n            if (part.executableCode) {\n                textStrings.push(\"\\n```\" +\n                    part.executableCode.language +\n                    \"\\n\" +\n                    part.executableCode.code +\n                    \"\\n```\\n\");\n            }\n            if (part.codeExecutionResult) {\n                textStrings.push(\"\\n```\\n\" + part.codeExecutionResult.output + \"\\n```\\n\");\n            }\n        }\n    }\n    if (textStrings.length > 0) {\n        return textStrings.join(\"\");\n    }\n    else {\n        return \"\";\n    }\n}\n/**\n * Returns functionCall of first candidate.\n */\nfunction getFunctionCalls(response) {\n    var _a, _b, _c, _d;\n    const functionCalls = [];\n    if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {\n        for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {\n            if (part.functionCall) {\n                functionCalls.push(part.functionCall);\n            }\n        }\n    }\n    if (functionCalls.length > 0) {\n        return functionCalls;\n    }\n    else {\n        return undefined;\n    }\n}\nconst badFinishReasons = [\n    FinishReason.RECITATION,\n    FinishReason.SAFETY,\n    FinishReason.LANGUAGE,\n];\nfunction hadBadFinishReason(candidate) {\n    return (!!candidate.finishReason &&\n        badFinishReasons.includes(candidate.finishReason));\n}\nfunction formatBlockErrorMessage(response) {\n    var _a, _b, _c;\n    let message = \"\";\n    if ((!response.candidates || response.candidates.length === 0) &&\n        response.promptFeedback) {\n        message += \"Response was blocked\";\n        if ((_a = response.promptFeedback) === null || _a === void 0 ? void 0 : _a.blockReason) {\n            message += ` due to ${response.promptFeedback.blockReason}`;\n        }\n        if ((_b = response.promptFeedback) === null || _b === void 0 ? void 0 : _b.blockReasonMessage) {\n            message += `: ${response.promptFeedback.blockReasonMessage}`;\n        }\n    }\n    else if ((_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0]) {\n        const firstCandidate = response.candidates[0];\n        if (hadBadFinishReason(firstCandidate)) {\n            message += `Candidate was blocked due to ${firstCandidate.finishReason}`;\n            if (firstCandidate.finishMessage) {\n                message += `: ${firstCandidate.finishMessage}`;\n            }\n        }\n    }\n    return message;\n}\n\n/******************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n/* global Reflect, Promise, SuppressedError, Symbol */\r\n\r\n\r\nfunction __await(v) {\r\n    return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n}\r\n\r\nfunction __asyncGenerator(thisArg, _arguments, generator) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n    function fulfill(value) { resume(\"next\", value); }\r\n    function reject(value) { resume(\"throw\", value); }\r\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n}\r\n\r\ntypeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\r\n    var e = new Error(message);\r\n    return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\r\n};\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst responseLineRE = /^data\\: (.*)(?:\\n\\n|\\r\\r|\\r\\n\\r\\n)/;\n/**\n * Process a response.body stream from the backend and return an\n * iterator that provides one complete GenerateContentResponse at a time\n * and a promise that resolves with a single aggregated\n * GenerateContentResponse.\n *\n * @param response - Response from a fetch call\n */\nfunction processStream(response) {\n    const inputStream = response.body.pipeThrough(new TextDecoderStream(\"utf8\", { fatal: true }));\n    const responseStream = getResponseStream(inputStream);\n    const [stream1, stream2] = responseStream.tee();\n    return {\n        stream: generateResponseSequence(stream1),\n        response: getResponsePromise(stream2),\n    };\n}\nasync function getResponsePromise(stream) {\n    const allResponses = [];\n    const reader = stream.getReader();\n    while (true) {\n        const { done, value } = await reader.read();\n        if (done) {\n            return addHelpers(aggregateResponses(allResponses));\n        }\n        allResponses.push(value);\n    }\n}\nfunction generateResponseSequence(stream) {\n    return __asyncGenerator(this, arguments, function* generateResponseSequence_1() {\n        const reader = stream.getReader();\n        while (true) {\n            const { value, done } = yield __await(reader.read());\n            if (done) {\n                break;\n            }\n            yield yield __await(addHelpers(value));\n        }\n    });\n}\n/**\n * Reads a raw stream from the fetch response and join incomplete\n * chunks, returning a new stream that provides a single complete\n * GenerateContentResponse in each iteration.\n */\nfunction getResponseStream(inputStream) {\n    const reader = inputStream.getReader();\n    const stream = new ReadableStream({\n        start(controller) {\n            let currentText = \"\";\n            return pump();\n            function pump() {\n                return reader\n                    .read()\n                    .then(({ value, done }) => {\n                    if (done) {\n                        if (currentText.trim()) {\n                            controller.error(new GoogleGenerativeAIError(\"Failed to parse stream\"));\n                            return;\n                        }\n                        controller.close();\n                        return;\n                    }\n                    currentText += value;\n                    let match = currentText.match(responseLineRE);\n                    let parsedResponse;\n                    while (match) {\n                        try {\n                            parsedResponse = JSON.parse(match[1]);\n                        }\n                        catch (e) {\n                            controller.error(new GoogleGenerativeAIError(`Error parsing JSON response: \"${match[1]}\"`));\n                            return;\n                        }\n                        controller.enqueue(parsedResponse);\n                        currentText = currentText.substring(match[0].length);\n                        match = currentText.match(responseLineRE);\n                    }\n                    return pump();\n                })\n                    .catch((e) => {\n                    let err = e;\n                    err.stack = e.stack;\n                    if (err.name === \"AbortError\") {\n                        err = new GoogleGenerativeAIAbortError(\"Request aborted when reading from the stream\");\n                    }\n                    else {\n                        err = new GoogleGenerativeAIError(\"Error reading from the stream\");\n                    }\n                    throw err;\n                });\n            }\n        },\n    });\n    return stream;\n}\n/**\n * Aggregates an array of `GenerateContentResponse`s into a single\n * GenerateContentResponse.\n */\nfunction aggregateResponses(responses) {\n    const lastResponse = responses[responses.length - 1];\n    const aggregatedResponse = {\n        promptFeedback: lastResponse === null || lastResponse === void 0 ? void 0 : lastResponse.promptFeedback,\n    };\n    for (const response of responses) {\n        if (response.candidates) {\n            let candidateIndex = 0;\n            for (const candidate of response.candidates) {\n                if (!aggregatedResponse.candidates) {\n                    aggregatedResponse.candidates = [];\n                }\n                if (!aggregatedResponse.candidates[candidateIndex]) {\n                    aggregatedResponse.candidates[candidateIndex] = {\n                        index: candidateIndex,\n                    };\n                }\n                // Keep overwriting, the last one will be final\n                aggregatedResponse.candidates[candidateIndex].citationMetadata =\n                    candidate.citationMetadata;\n                aggregatedResponse.candidates[candidateIndex].groundingMetadata =\n                    candidate.groundingMetadata;\n                aggregatedResponse.candidates[candidateIndex].finishReason =\n                    candidate.finishReason;\n                aggregatedResponse.candidates[candidateIndex].finishMessage =\n                    candidate.finishMessage;\n                aggregatedResponse.candidates[candidateIndex].safetyRatings =\n                    candidate.safetyRatings;\n                /**\n                 * Candidates should always have content and parts, but this handles\n                 * possible malformed responses.\n                 */\n                if (candidate.content && candidate.content.parts) {\n                    if (!aggregatedResponse.candidates[candidateIndex].content) {\n                        aggregatedResponse.candidates[candidateIndex].content = {\n                            role: candidate.content.role || \"user\",\n                            parts: [],\n                        };\n                    }\n                    const newPart = {};\n                    for (const part of candidate.content.parts) {\n                        if (part.text) {\n                            newPart.text = part.text;\n                        }\n                        if (part.functionCall) {\n                            newPart.functionCall = part.functionCall;\n                        }\n                        if (part.executableCode) {\n                            newPart.executableCode = part.executableCode;\n                        }\n                        if (part.codeExecutionResult) {\n                            newPart.codeExecutionResult = part.codeExecutionResult;\n                        }\n                        if (Object.keys(newPart).length === 0) {\n                            newPart.text = \"\";\n                        }\n                        aggregatedResponse.candidates[candidateIndex].content.parts.push(newPart);\n                    }\n                }\n            }\n            candidateIndex++;\n        }\n        if (response.usageMetadata) {\n            aggregatedResponse.usageMetadata = response.usageMetadata;\n        }\n    }\n    return aggregatedResponse;\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nasync function generateContentStream(apiKey, model, params, requestOptions) {\n    const response = await makeModelRequest(model, Task.STREAM_GENERATE_CONTENT, apiKey, \n    /* stream */ true, JSON.stringify(params), requestOptions);\n    return processStream(response);\n}\nasync function generateContent(apiKey, model, params, requestOptions) {\n    const response = await makeModelRequest(model, Task.GENERATE_CONTENT, apiKey, \n    /* stream */ false, JSON.stringify(params), requestOptions);\n    const responseJson = await response.json();\n    const enhancedResponse = addHelpers(responseJson);\n    return {\n        response: enhancedResponse,\n    };\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nfunction formatSystemInstruction(input) {\n    // null or undefined\n    if (input == null) {\n        return undefined;\n    }\n    else if (typeof input === \"string\") {\n        return { role: \"system\", parts: [{ text: input }] };\n    }\n    else if (input.text) {\n        return { role: \"system\", parts: [input] };\n    }\n    else if (input.parts) {\n        if (!input.role) {\n            return { role: \"system\", parts: input.parts };\n        }\n        else {\n            return input;\n        }\n    }\n}\nfunction formatNewContent(request) {\n    let newParts = [];\n    if (typeof request === \"string\") {\n        newParts = [{ text: request }];\n    }\n    else {\n        for (const partOrString of request) {\n            if (typeof partOrString === \"string\") {\n                newParts.push({ text: partOrString });\n            }\n            else {\n                newParts.push(partOrString);\n            }\n        }\n    }\n    return assignRoleToPartsAndValidateSendMessageRequest(newParts);\n}\n/**\n * When multiple Part types (i.e. FunctionResponsePart and TextPart) are\n * passed in a single Part array, we may need to assign different roles to each\n * part. Currently only FunctionResponsePart requires a role other than 'user'.\n * @private\n * @param parts Array of parts to pass to the model\n * @returns Array of content items\n */\nfunction assignRoleToPartsAndValidateSendMessageRequest(parts) {\n    const userContent = { role: \"user\", parts: [] };\n    const functionContent = { role: \"function\", parts: [] };\n    let hasUserContent = false;\n    let hasFunctionContent = false;\n    for (const part of parts) {\n        if (\"functionResponse\" in part) {\n            functionContent.parts.push(part);\n            hasFunctionContent = true;\n        }\n        else {\n            userContent.parts.push(part);\n            hasUserContent = true;\n        }\n    }\n    if (hasUserContent && hasFunctionContent) {\n        throw new GoogleGenerativeAIError(\"Within a single message, FunctionResponse cannot be mixed with other type of part in the request for sending chat message.\");\n    }\n    if (!hasUserContent && !hasFunctionContent) {\n        throw new GoogleGenerativeAIError(\"No content is provided for sending chat message.\");\n    }\n    if (hasUserContent) {\n        return userContent;\n    }\n    return functionContent;\n}\nfunction formatCountTokensInput(params, modelParams) {\n    var _a;\n    let formattedGenerateContentRequest = {\n        model: modelParams === null || modelParams === void 0 ? void 0 : modelParams.model,\n        generationConfig: modelParams === null || modelParams === void 0 ? void 0 : modelParams.generationConfig,\n        safetySettings: modelParams === null || modelParams === void 0 ? void 0 : modelParams.safetySettings,\n        tools: modelParams === null || modelParams === void 0 ? void 0 : modelParams.tools,\n        toolConfig: modelParams === null || modelParams === void 0 ? void 0 : modelParams.toolConfig,\n        systemInstruction: modelParams === null || modelParams === void 0 ? void 0 : modelParams.systemInstruction,\n        cachedContent: (_a = modelParams === null || modelParams === void 0 ? void 0 : modelParams.cachedContent) === null || _a === void 0 ? void 0 : _a.name,\n        contents: [],\n    };\n    const containsGenerateContentRequest = params.generateContentRequest != null;\n    if (params.contents) {\n        if (containsGenerateContentRequest) {\n            throw new GoogleGenerativeAIRequestInputError(\"CountTokensRequest must have one of contents or generateContentRequest, not both.\");\n        }\n        formattedGenerateContentRequest.contents = params.contents;\n    }\n    else if (containsGenerateContentRequest) {\n        formattedGenerateContentRequest = Object.assign(Object.assign({}, formattedGenerateContentRequest), params.generateContentRequest);\n    }\n    else {\n        // Array or string\n        const content = formatNewContent(params);\n        formattedGenerateContentRequest.contents = [content];\n    }\n    return { generateContentRequest: formattedGenerateContentRequest };\n}\nfunction formatGenerateContentInput(params) {\n    let formattedRequest;\n    if (params.contents) {\n        formattedRequest = params;\n    }\n    else {\n        // Array or string\n        const content = formatNewContent(params);\n        formattedRequest = { contents: [content] };\n    }\n    if (params.systemInstruction) {\n        formattedRequest.systemInstruction = formatSystemInstruction(params.systemInstruction);\n    }\n    return formattedRequest;\n}\nfunction formatEmbedContentInput(params) {\n    if (typeof params === \"string\" || Array.isArray(params)) {\n        const content = formatNewContent(params);\n        return { content };\n    }\n    return params;\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// https://ai.google.dev/api/rest/v1beta/Content#part\nconst VALID_PART_FIELDS = [\n    \"text\",\n    \"inlineData\",\n    \"functionCall\",\n    \"functionResponse\",\n    \"executableCode\",\n    \"codeExecutionResult\",\n];\nconst VALID_PARTS_PER_ROLE = {\n    user: [\"text\", \"inlineData\"],\n    function: [\"functionResponse\"],\n    model: [\"text\", \"functionCall\", \"executableCode\", \"codeExecutionResult\"],\n    // System instructions shouldn't be in history anyway.\n    system: [\"text\"],\n};\nfunction validateChatHistory(history) {\n    let prevContent = false;\n    for (const currContent of history) {\n        const { role, parts } = currContent;\n        if (!prevContent && role !== \"user\") {\n            throw new GoogleGenerativeAIError(`First content should be with role 'user', got ${role}`);\n        }\n        if (!POSSIBLE_ROLES.includes(role)) {\n            throw new GoogleGenerativeAIError(`Each item should include role field. Got ${role} but valid roles are: ${JSON.stringify(POSSIBLE_ROLES)}`);\n        }\n        if (!Array.isArray(parts)) {\n            throw new GoogleGenerativeAIError(\"Content should have 'parts' property with an array of Parts\");\n        }\n        if (parts.length === 0) {\n            throw new GoogleGenerativeAIError(\"Each Content should have at least one part\");\n        }\n        const countFields = {\n            text: 0,\n            inlineData: 0,\n            functionCall: 0,\n            functionResponse: 0,\n            fileData: 0,\n            executableCode: 0,\n            codeExecutionResult: 0,\n        };\n        for (const part of parts) {\n            for (const key of VALID_PART_FIELDS) {\n                if (key in part) {\n                    countFields[key] += 1;\n                }\n            }\n        }\n        const validParts = VALID_PARTS_PER_ROLE[role];\n        for (const key of VALID_PART_FIELDS) {\n            if (!validParts.includes(key) && countFields[key] > 0) {\n                throw new GoogleGenerativeAIError(`Content with role '${role}' can't contain '${key}' part`);\n            }\n        }\n        prevContent = true;\n    }\n}\n/**\n * Returns true if the response is valid (could be appended to the history), flase otherwise.\n */\nfunction isValidResponse(response) {\n    var _a;\n    if (response.candidates === undefined || response.candidates.length === 0) {\n        return false;\n    }\n    const content = (_a = response.candidates[0]) === null || _a === void 0 ? void 0 : _a.content;\n    if (content === undefined) {\n        return false;\n    }\n    if (content.parts === undefined || content.parts.length === 0) {\n        return false;\n    }\n    for (const part of content.parts) {\n        if (part === undefined || Object.keys(part).length === 0) {\n            return false;\n        }\n        if (part.text !== undefined && part.text === \"\") {\n            return false;\n        }\n    }\n    return true;\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Do not log a message for this error.\n */\nconst SILENT_ERROR = \"SILENT_ERROR\";\n/**\n * ChatSession class that enables sending chat messages and stores\n * history of sent and received messages so far.\n *\n * @public\n */\nclass ChatSession {\n    constructor(apiKey, model, params, _requestOptions = {}) {\n        this.model = model;\n        this.params = params;\n        this._requestOptions = _requestOptions;\n        this._history = [];\n        this._sendPromise = Promise.resolve();\n        this._apiKey = apiKey;\n        if (params === null || params === void 0 ? void 0 : params.history) {\n            validateChatHistory(params.history);\n            this._history = params.history;\n        }\n    }\n    /**\n     * Gets the chat history so far. Blocked prompts are not added to history.\n     * Blocked candidates are not added to history, nor are the prompts that\n     * generated them.\n     */\n    async getHistory() {\n        await this._sendPromise;\n        return this._history;\n    }\n    /**\n     * Sends a chat message and receives a non-streaming\n     * {@link GenerateContentResult}.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async sendMessage(request, requestOptions = {}) {\n        var _a, _b, _c, _d, _e, _f;\n        await this._sendPromise;\n        const newContent = formatNewContent(request);\n        const generateContentRequest = {\n            safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,\n            generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,\n            tools: (_c = this.params) === null || _c === void 0 ? void 0 : _c.tools,\n            toolConfig: (_d = this.params) === null || _d === void 0 ? void 0 : _d.toolConfig,\n            systemInstruction: (_e = this.params) === null || _e === void 0 ? void 0 : _e.systemInstruction,\n            cachedContent: (_f = this.params) === null || _f === void 0 ? void 0 : _f.cachedContent,\n            contents: [...this._history, newContent],\n        };\n        const chatSessionRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        let finalResult;\n        // Add onto the chain.\n        this._sendPromise = this._sendPromise\n            .then(() => generateContent(this._apiKey, this.model, generateContentRequest, chatSessionRequestOptions))\n            .then((result) => {\n            var _a;\n            if (isValidResponse(result.response)) {\n                this._history.push(newContent);\n                const responseContent = Object.assign({ parts: [], \n                    // Response seems to come back without a role set.\n                    role: \"model\" }, (_a = result.response.candidates) === null || _a === void 0 ? void 0 : _a[0].content);\n                this._history.push(responseContent);\n            }\n            else {\n                const blockErrorMessage = formatBlockErrorMessage(result.response);\n                if (blockErrorMessage) {\n                    console.warn(`sendMessage() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);\n                }\n            }\n            finalResult = result;\n        })\n            .catch((e) => {\n            // Resets _sendPromise to avoid subsequent calls failing and throw error.\n            this._sendPromise = Promise.resolve();\n            throw e;\n        });\n        await this._sendPromise;\n        return finalResult;\n    }\n    /**\n     * Sends a chat message and receives the response as a\n     * {@link GenerateContentStreamResult} containing an iterable stream\n     * and a response promise.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async sendMessageStream(request, requestOptions = {}) {\n        var _a, _b, _c, _d, _e, _f;\n        await this._sendPromise;\n        const newContent = formatNewContent(request);\n        const generateContentRequest = {\n            safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,\n            generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,\n            tools: (_c = this.params) === null || _c === void 0 ? void 0 : _c.tools,\n            toolConfig: (_d = this.params) === null || _d === void 0 ? void 0 : _d.toolConfig,\n            systemInstruction: (_e = this.params) === null || _e === void 0 ? void 0 : _e.systemInstruction,\n            cachedContent: (_f = this.params) === null || _f === void 0 ? void 0 : _f.cachedContent,\n            contents: [...this._history, newContent],\n        };\n        const chatSessionRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        const streamPromise = generateContentStream(this._apiKey, this.model, generateContentRequest, chatSessionRequestOptions);\n        // Add onto the chain.\n        this._sendPromise = this._sendPromise\n            .then(() => streamPromise)\n            // This must be handled to avoid unhandled rejection, but jump\n            // to the final catch block with a label to not log this error.\n            .catch((_ignored) => {\n            throw new Error(SILENT_ERROR);\n        })\n            .then((streamResult) => streamResult.response)\n            .then((response) => {\n            if (isValidResponse(response)) {\n                this._history.push(newContent);\n                const responseContent = Object.assign({}, response.candidates[0].content);\n                // Response seems to come back without a role set.\n                if (!responseContent.role) {\n                    responseContent.role = \"model\";\n                }\n                this._history.push(responseContent);\n            }\n            else {\n                const blockErrorMessage = formatBlockErrorMessage(response);\n                if (blockErrorMessage) {\n                    console.warn(`sendMessageStream() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);\n                }\n            }\n        })\n            .catch((e) => {\n            // Errors in streamPromise are already catchable by the user as\n            // streamPromise is returned.\n            // Avoid duplicating the error message in logs.\n            if (e.message !== SILENT_ERROR) {\n                // Users do not have access to _sendPromise to catch errors\n                // downstream from streamPromise, so they should not throw.\n                console.error(e);\n            }\n        });\n        return streamPromise;\n    }\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nasync function countTokens(apiKey, model, params, singleRequestOptions) {\n    const response = await makeModelRequest(model, Task.COUNT_TOKENS, apiKey, false, JSON.stringify(params), singleRequestOptions);\n    return response.json();\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nasync function embedContent(apiKey, model, params, requestOptions) {\n    const response = await makeModelRequest(model, Task.EMBED_CONTENT, apiKey, false, JSON.stringify(params), requestOptions);\n    return response.json();\n}\nasync function batchEmbedContents(apiKey, model, params, requestOptions) {\n    const requestsWithModel = params.requests.map((request) => {\n        return Object.assign(Object.assign({}, request), { model });\n    });\n    const response = await makeModelRequest(model, Task.BATCH_EMBED_CONTENTS, apiKey, false, JSON.stringify({ requests: requestsWithModel }), requestOptions);\n    return response.json();\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Class for generative model APIs.\n * @public\n */\nclass GenerativeModel {\n    constructor(apiKey, modelParams, _requestOptions = {}) {\n        this.apiKey = apiKey;\n        this._requestOptions = _requestOptions;\n        if (modelParams.model.includes(\"/\")) {\n            // Models may be named \"models/model-name\" or \"tunedModels/model-name\"\n            this.model = modelParams.model;\n        }\n        else {\n            // If path is not included, assume it's a non-tuned model.\n            this.model = `models/${modelParams.model}`;\n        }\n        this.generationConfig = modelParams.generationConfig || {};\n        this.safetySettings = modelParams.safetySettings || [];\n        this.tools = modelParams.tools;\n        this.toolConfig = modelParams.toolConfig;\n        this.systemInstruction = formatSystemInstruction(modelParams.systemInstruction);\n        this.cachedContent = modelParams.cachedContent;\n    }\n    /**\n     * Makes a single non-streaming call to the model\n     * and returns an object containing a single {@link GenerateContentResponse}.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async generateContent(request, requestOptions = {}) {\n        var _a;\n        const formattedParams = formatGenerateContentInput(request);\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return generateContent(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, formattedParams), generativeModelRequestOptions);\n    }\n    /**\n     * Makes a single streaming call to the model and returns an object\n     * containing an iterable stream that iterates over all chunks in the\n     * streaming response as well as a promise that returns the final\n     * aggregated response.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async generateContentStream(request, requestOptions = {}) {\n        var _a;\n        const formattedParams = formatGenerateContentInput(request);\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return generateContentStream(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, formattedParams), generativeModelRequestOptions);\n    }\n    /**\n     * Gets a new {@link ChatSession} instance which can be used for\n     * multi-turn chats.\n     */\n    startChat(startChatParams) {\n        var _a;\n        return new ChatSession(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, startChatParams), this._requestOptions);\n    }\n    /**\n     * Counts the tokens in the provided request.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async countTokens(request, requestOptions = {}) {\n        const formattedParams = formatCountTokensInput(request, {\n            model: this.model,\n            generationConfig: this.generationConfig,\n            safetySettings: this.safetySettings,\n            tools: this.tools,\n            toolConfig: this.toolConfig,\n            systemInstruction: this.systemInstruction,\n            cachedContent: this.cachedContent,\n        });\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return countTokens(this.apiKey, this.model, formattedParams, generativeModelRequestOptions);\n    }\n    /**\n     * Embeds the provided content.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async embedContent(request, requestOptions = {}) {\n        const formattedParams = formatEmbedContentInput(request);\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return embedContent(this.apiKey, this.model, formattedParams, generativeModelRequestOptions);\n    }\n    /**\n     * Embeds an array of {@link EmbedContentRequest}s.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async batchEmbedContents(batchEmbedContentRequest, requestOptions = {}) {\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return batchEmbedContents(this.apiKey, this.model, batchEmbedContentRequest, generativeModelRequestOptions);\n    }\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Top-level class for this SDK\n * @public\n */\nclass GoogleGenerativeAI {\n    constructor(apiKey) {\n        this.apiKey = apiKey;\n    }\n    /**\n     * Gets a {@link GenerativeModel} instance for the provided model name.\n     */\n    getGenerativeModel(modelParams, requestOptions) {\n        if (!modelParams.model) {\n            throw new GoogleGenerativeAIError(`Must provide a model name. ` +\n                `Example: genai.getGenerativeModel({ model: 'my-model-name' })`);\n        }\n        return new GenerativeModel(this.apiKey, modelParams, requestOptions);\n    }\n    /**\n     * Creates a {@link GenerativeModel} instance from provided content cache.\n     */\n    getGenerativeModelFromCachedContent(cachedContent, modelParams, requestOptions) {\n        if (!cachedContent.name) {\n            throw new GoogleGenerativeAIRequestInputError(\"Cached content must contain a `name` field.\");\n        }\n        if (!cachedContent.model) {\n            throw new GoogleGenerativeAIRequestInputError(\"Cached content must contain a `model` field.\");\n        }\n        /**\n         * Not checking tools and toolConfig for now as it would require a deep\n         * equality comparison and isn't likely to be a common case.\n         */\n        const disallowedDuplicates = [\"model\", \"systemInstruction\"];\n        for (const key of disallowedDuplicates) {\n            if ((modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) &&\n                cachedContent[key] &&\n                (modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) !== cachedContent[key]) {\n                if (key === \"model\") {\n                    const modelParamsComp = modelParams.model.startsWith(\"models/\")\n                        ? modelParams.model.replace(\"models/\", \"\")\n                        : modelParams.model;\n                    const cachedContentComp = cachedContent.model.startsWith(\"models/\")\n                        ? cachedContent.model.replace(\"models/\", \"\")\n                        : cachedContent.model;\n                    if (modelParamsComp === cachedContentComp) {\n                        continue;\n                    }\n                }\n                throw new GoogleGenerativeAIRequestInputError(`Different value for \"${key}\" specified in modelParams` +\n                    ` (${modelParams[key]}) and cachedContent (${cachedContent[key]})`);\n            }\n        }\n        const modelParamsFromCache = Object.assign(Object.assign({}, modelParams), { model: cachedContent.model, tools: cachedContent.tools, toolConfig: cachedContent.toolConfig, systemInstruction: cachedContent.systemInstruction, cachedContent });\n        return new GenerativeModel(this.apiKey, modelParamsFromCache, requestOptions);\n    }\n}\n\nexport { BlockReason, ChatSession, DynamicRetrievalMode, ExecutableCodeLanguage, FinishReason, FunctionCallingMode, GenerativeModel, GoogleGenerativeAI, GoogleGenerativeAIAbortError, GoogleGenerativeAIError, GoogleGenerativeAIFetchError, GoogleGenerativeAIRequestInputError, GoogleGenerativeAIResponseError, HarmBlockThreshold, HarmCategory, HarmProbability, Outcome, POSSIBLE_ROLES, SchemaType, TaskType };\n//# sourceMappingURL=index.mjs.map\n","/**\n * Glide  Settings Service\n *\n * Manages user preferences and API configuration.\n * Persists settings to localStorage (syncs automatically across sessions).\n *\n *  Rizonetech (Pty) Ltd.  https://rizonesoft.com\n */\n\nimport { initGeminiClient } from '../services/gemini';\n\n// ---------------------------------------------------------------------------\n// Types\n// ---------------------------------------------------------------------------\n\n/** Tone options available across Draft and Reply features. */\nexport type Tone = 'professional' | 'formal' | 'friendly' | 'casual';\n\n/** Summary style options for the Summarize feature. */\nexport type SummaryStyle = 'bullets' | 'paragraph' | 'tldr';\n\n/** All persisted user preferences. */\nexport interface GlideSettings {\n  /** Google Gemini API key (stored in plain text in localStorage). */\n  apiKey: string;\n  /** Gemini model to use for all features. */\n  defaultModel: string;\n  /** Default tone for Draft Email and Reply. */\n  defaultTone: Tone;\n  /** Default summary style for Summarize. */\n  defaultSummaryStyle: SummaryStyle;\n  /** Default target language for Translate. */\n  defaultLanguage: string;\n}\n\n// ---------------------------------------------------------------------------\n// Defaults\n// ---------------------------------------------------------------------------\n\nconst STORAGE_KEY = 'glide_settings';\n\nconst DEFAULT_SETTINGS: GlideSettings = {\n  apiKey: '',\n  defaultModel: 'gemini-3-flash-preview',\n  defaultTone: 'professional',\n  defaultSummaryStyle: 'bullets',\n  defaultLanguage: 'English',\n};\n\n// ---------------------------------------------------------------------------\n// In-memory cache\n// ---------------------------------------------------------------------------\n\nlet cached: GlideSettings | null = null;\n\n// ---------------------------------------------------------------------------\n// Public API\n// ---------------------------------------------------------------------------\n\n/**\n * Load settings from localStorage (or return defaults).\n */\nexport function loadSettings(): GlideSettings {\n  if (cached) return { ...cached };\n\n  try {\n    const raw = localStorage.getItem(STORAGE_KEY);\n    if (raw) {\n      const parsed = JSON.parse(raw) as Partial<GlideSettings>;\n      cached = { ...DEFAULT_SETTINGS, ...parsed };\n    } else {\n      cached = { ...DEFAULT_SETTINGS };\n    }\n  } catch {\n    cached = { ...DEFAULT_SETTINGS };\n  }\n\n  return { ...cached };\n}\n\n/**\n * Save settings to localStorage and update the in-memory cache.\n * If the API key changed, automatically re-initializes the Gemini client.\n */\nexport function saveSettings(settings: GlideSettings): void {\n  const previousKey = cached?.apiKey || '';\n\n  cached = { ...settings };\n\n  try {\n    localStorage.setItem(STORAGE_KEY, JSON.stringify(cached));\n  } catch {\n    // localStorage might be unavailable in some sandboxed environments\n  }\n\n  // Re-initialize Gemini client if the API key changed\n  if (settings.apiKey && settings.apiKey !== previousKey) {\n    try {\n      initGeminiClient(settings.apiKey);\n    } catch {\n      // Will be retried on next action\n    }\n  }\n}\n\n/**\n * Get the current API key (loads settings if not cached).\n */\nexport function getApiKey(): string {\n  return loadSettings().apiKey;\n}\n\n/**\n * Update just the API key (convenience method).\n */\nexport function setApiKey(key: string): void {\n  const settings = loadSettings();\n  settings.apiKey = key;\n  saveSettings(settings);\n}\n\n/**\n * Get a single setting value.\n */\nexport function getSetting<K extends keyof GlideSettings>(key: K): GlideSettings[K] {\n  return loadSettings()[key];\n}\n\n/**\n * Reset all settings to defaults and clear localStorage.\n */\nexport function resetSettings(): void {\n  cached = { ...DEFAULT_SETTINGS };\n  try {\n    localStorage.removeItem(STORAGE_KEY);\n  } catch {\n    // Ignore\n  }\n}\n","/**\n * Glide  Gemini Client Service\n *\n * Provides a typed interface to the Google Generative AI (Gemini) API\n * with configurable parameters, rate-limiting with exponential backoff,\n * and granular error handling.\n *\n *  Rizonetech (Pty) Ltd.  https://rizonesoft.com\n */\n\nimport { GoogleGenerativeAI, GenerativeModel, GenerationConfig } from '@google/generative-ai';\nimport { getSetting } from '../features/settings';\n\n// ---------------------------------------------------------------------------\n// Types\n// ---------------------------------------------------------------------------\n\n/** Configurable generation options passed to `generateText`. */\nexport interface GenerateOptions {\n  /** Controls randomness. Lower = more deterministic. Range: 0.02.0. Default: 1.0 */\n  temperature?: number;\n  /** Maximum number of tokens in the response. Default: 2048 */\n  maxOutputTokens?: number;\n  /** Nucleus sampling. Range: 0.01.0. Default: 0.95 */\n  topP?: number;\n  /** Top-K sampling. Default: 40 */\n  topK?: number;\n  /** Which Gemini model to use. Default: user's saved setting or 'gemini-2.5-flash' */\n  model?: string;\n}\n\n/** Error codes surfaced by the Gemini service. */\nexport enum GeminiErrorCode {\n  INVALID_API_KEY = 'INVALID_API_KEY',\n  QUOTA_EXCEEDED = 'QUOTA_EXCEEDED',\n  RATE_LIMITED = 'RATE_LIMITED',\n  NETWORK_ERROR = 'NETWORK_ERROR',\n  TIMEOUT = 'TIMEOUT',\n  CONTENT_FILTERED = 'CONTENT_FILTERED',\n  UNKNOWN = 'UNKNOWN',\n}\n\n/** Typed error thrown by the Gemini service. */\nexport class GeminiError extends Error {\n  code: GeminiErrorCode;\n  retryable: boolean;\n  statusCode?: number;\n\n  constructor(message: string, code: GeminiErrorCode, retryable = false, statusCode?: number) {\n    super(message);\n    this.name = 'GeminiError';\n    this.code = code;\n    this.retryable = retryable;\n    this.statusCode = statusCode;\n    // Fix prototype chain for ES5 targets (TypeScript class extending Error)\n    Object.setPrototypeOf(this, GeminiError.prototype);\n  }\n}\n\n// ---------------------------------------------------------------------------\n// Constants\n// ---------------------------------------------------------------------------\n\nconst FALLBACK_MODEL = 'gemini-3-flash-preview';\nconst DEFAULT_TEMPERATURE = 1.0;\nconst DEFAULT_MAX_OUTPUT_TOKENS = 2048;\nconst DEFAULT_TOP_P = 0.95;\nconst DEFAULT_TOP_K = 40;\n\nconst MAX_RETRIES = 3;\nconst INITIAL_RETRY_DELAY_MS = 1000;\nconst RETRY_BACKOFF_FACTOR = 2;\nconst REQUEST_TIMEOUT_MS = 30_000;\n\n// ---------------------------------------------------------------------------\n// Client singleton\n// ---------------------------------------------------------------------------\n\nlet clientInstance: GoogleGenerativeAI | null = null;\n\n/**\n * Initialise (or reinitialise) the Gemini client with the given API key.\n * Returns the `GoogleGenerativeAI` instance for direct access if needed.\n */\nexport function initGeminiClient(apiKey: string): GoogleGenerativeAI {\n  if (!apiKey || apiKey.trim().length === 0) {\n    throw new GeminiError(\n      'API key is required. Please set GEMINI_API_KEY in your .env file.',\n      GeminiErrorCode.INVALID_API_KEY,\n    );\n  }\n  clientInstance = new GoogleGenerativeAI(apiKey);\n  return clientInstance;\n}\n\n/**\n * Returns the current client instance, or throws if `initGeminiClient`\n * has not been called yet.\n */\nfunction getClient(): GoogleGenerativeAI {\n  if (!clientInstance) {\n    throw new GeminiError(\n      'Gemini client not initialised. Call initGeminiClient(apiKey) first.',\n      GeminiErrorCode.INVALID_API_KEY,\n    );\n  }\n  return clientInstance;\n}\n\n// ---------------------------------------------------------------------------\n// Core generation function\n// ---------------------------------------------------------------------------\n\n/**\n * Send a prompt to Gemini and return the generated text.\n *\n * @param prompt  - The user prompt string.\n * @param options - Optional generation parameters.\n * @returns The model's text response.\n *\n * @throws {GeminiError} with a typed `code` for every failure scenario.\n */\nexport async function generateText(\n  prompt: string,\n  options: GenerateOptions = {},\n): Promise<string> {\n  const client = getClient();\n  const modelName = options.model ?? getSetting('defaultModel') ?? FALLBACK_MODEL;\n\n  const generationConfig: GenerationConfig = {\n    temperature: options.temperature ?? DEFAULT_TEMPERATURE,\n    maxOutputTokens: options.maxOutputTokens ?? DEFAULT_MAX_OUTPUT_TOKENS,\n    topP: options.topP ?? DEFAULT_TOP_P,\n    topK: options.topK ?? DEFAULT_TOP_K,\n  };\n\n  const model: GenerativeModel = client.getGenerativeModel({\n    model: modelName,\n    generationConfig,\n  });\n\n  return retryWithBackoff(() => callModel(model, prompt));\n}\n\n// ---------------------------------------------------------------------------\n// Internal helpers\n// ---------------------------------------------------------------------------\n\n/** Make a single API call with a timeout wrapper. */\nasync function callModel(model: GenerativeModel, prompt: string): Promise<string> {\n  try {\n    const result = await withTimeout(model.generateContent(prompt), REQUEST_TIMEOUT_MS);\n\n    const response = result.response;\n    const text = response.text();\n\n    if (!text || text.trim().length === 0) {\n      throw new GeminiError(\n        'The model returned an empty response. The content may have been filtered.',\n        GeminiErrorCode.CONTENT_FILTERED,\n      );\n    }\n\n    return text;\n  } catch (error) {\n    throw classifyError(error);\n  }\n}\n\n/** Wrap a promise with a timeout. */\nfunction withTimeout<T>(promise: Promise<T>, ms: number): Promise<T> {\n  return new Promise<T>((resolve, reject) => {\n    const timer = setTimeout(() => {\n      reject(\n        new GeminiError(\n          `Request timed out after ${ms / 1000}s. Check your network connection.`,\n          GeminiErrorCode.TIMEOUT,\n          true,\n        ),\n      );\n    }, ms);\n\n    promise\n      .then((value) => {\n        clearTimeout(timer);\n        resolve(value);\n      })\n      .catch((err) => {\n        clearTimeout(timer);\n        reject(err);\n      });\n  });\n}\n\n/**\n * Retry a function with exponential backoff.\n * Only retries errors marked as `retryable`.\n */\nasync function retryWithBackoff(fn: () => Promise<string>): Promise<string> {\n  let lastError: GeminiError | undefined;\n  let delay = INITIAL_RETRY_DELAY_MS;\n\n  for (let attempt = 0; attempt <= MAX_RETRIES; attempt++) {\n    try {\n      return await fn();\n    } catch (error) {\n      lastError = error instanceof GeminiError ? error : classifyError(error);\n\n      if (!lastError.retryable || attempt === MAX_RETRIES) {\n        throw lastError;\n      }\n\n      // Wait with jitter before retrying\n      const jitter = Math.random() * 0.3 * delay;\n      await sleep(delay + jitter);\n      delay *= RETRY_BACKOFF_FACTOR;\n    }\n  }\n\n  // Should never reach here, but TypeScript needs it\n  throw lastError!;\n}\n\n/** Classify raw errors into typed GeminiError instances. */\nfunction classifyError(error: unknown): GeminiError {\n  // Already classified\n  if (error instanceof GeminiError) {\n    return error;\n  }\n\n  const message = error instanceof Error ? error.message : String(error);\n  const statusCode = extractStatusCode(error);\n\n  // Invalid / expired API key\n  if (statusCode === 401 || statusCode === 403 || /api.?key/i.test(message)) {\n    return new GeminiError(\n      'Invalid or expired API key. Please check your GEMINI_API_KEY.',\n      GeminiErrorCode.INVALID_API_KEY,\n      false,\n      statusCode,\n    );\n  }\n\n  // Rate limited\n  if (statusCode === 429 || /rate.?limit/i.test(message) || /too many requests/i.test(message)) {\n    return new GeminiError(\n      'Rate limited by the Gemini API. Retrying with backoff',\n      GeminiErrorCode.RATE_LIMITED,\n      true,\n      429,\n    );\n  }\n\n  // Quota exceeded\n  if (statusCode === 429 && /quota/i.test(message)) {\n    return new GeminiError(\n      'API quota exceeded. Check your billing and quota settings in the Google Cloud Console.',\n      GeminiErrorCode.QUOTA_EXCEEDED,\n      false,\n      429,\n    );\n  }\n\n  // Network errors\n  if (\n    /network/i.test(message) ||\n    /fetch failed/i.test(message) ||\n    /ECONNREFUSED/i.test(message) ||\n    /ENOTFOUND/i.test(message) ||\n    /offline/i.test(message)\n  ) {\n    return new GeminiError(\n      'Network error  please check your internet connection.',\n      GeminiErrorCode.NETWORK_ERROR,\n      true,\n    );\n  }\n\n  // Content safety filter\n  if (/safety/i.test(message) || /blocked/i.test(message) || /filter/i.test(message)) {\n    return new GeminiError(\n      'The response was blocked by content safety filters.',\n      GeminiErrorCode.CONTENT_FILTERED,\n      false,\n    );\n  }\n\n  // Server errors (5xx) are retryable\n  if (statusCode && statusCode >= 500) {\n    return new GeminiError(\n      `Server error (${statusCode}). Retrying`,\n      GeminiErrorCode.UNKNOWN,\n      true,\n      statusCode,\n    );\n  }\n\n  // Unknown\n  return new GeminiError(\n    `Unexpected error: ${message}`,\n    GeminiErrorCode.UNKNOWN,\n    false,\n    statusCode,\n  );\n}\n\n/** Try to extract an HTTP status code from an error object. */\nfunction extractStatusCode(error: unknown): number | undefined {\n  if (error && typeof error === 'object') {\n    const obj = error as Record<string, unknown>;\n    if (typeof obj.status === 'number') return obj.status;\n    if (typeof obj.statusCode === 'number') return obj.statusCode;\n    if (typeof obj.code === 'number') return obj.code;\n    // Google AI SDK sometimes nests it\n    if (obj.response && typeof obj.response === 'object') {\n      const resp = obj.response as Record<string, unknown>;\n      if (typeof resp.status === 'number') return resp.status;\n    }\n  }\n  return undefined;\n}\n\n/** Promise-based sleep. */\nfunction sleep(ms: number): Promise<void> {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\n","/**\n * Glide  Prompt Builder\n *\n * Utilities for constructing prompts from templates with variable\n * substitution and safe context truncation.\n *\n *  Rizonetech (Pty) Ltd.  https://rizonesoft.com\n */\n\n// ---------------------------------------------------------------------------\n// Types\n// ---------------------------------------------------------------------------\n\n/** A record of placeholder names (without braces) to their values. */\nexport type PromptVariables = Record<string, string>;\n\n// ---------------------------------------------------------------------------\n// Constants\n// ---------------------------------------------------------------------------\n\n/**\n * Rough estimate: 1 token  4 characters for English text.\n * This is a conservative approximation used for truncation.\n */\nconst CHARS_PER_TOKEN = 4;\n\n/** Suffix appended when text is truncated. */\nconst TRUNCATION_SUFFIX = '\\n\\n[Content truncated due to length]';\n\n// ---------------------------------------------------------------------------\n// Public API\n// ---------------------------------------------------------------------------\n\n/**\n * Replace `{{PLACEHOLDER}}` markers in a template with the provided values.\n *\n * - Placeholders are case-sensitive and matched exactly.\n * - Missing variables are left as-is (e.g. `{{UNKNOWN}}` stays in the output).\n * - Extra variables not present in the template are silently ignored.\n *\n * @param template  - The prompt template string with `{{VAR}}` placeholders.\n * @param variables - A key-value map of placeholder names to replacement values.\n * @returns The fully interpolated prompt string.\n *\n * @example\n * ```ts\n * buildPrompt('Hello {{NAME}}, your order {{ID}} is ready.', {\n *   NAME: 'Alice',\n *   ID: '12345',\n * });\n * //  'Hello Alice, your order 12345 is ready.'\n * ```\n */\nexport function buildPrompt(template: string, variables: PromptVariables): string {\n  if (!template) {\n    throw new Error('Prompt template cannot be empty.');\n  }\n\n  let result = template;\n\n  for (const [key, value] of Object.entries(variables)) {\n    // Replace all occurrences of {{KEY}} with the provided value\n    const placeholder = `{{${key}}}`;\n    result = result.split(placeholder).join(value);\n  }\n\n  return result;\n}\n\n/**\n * Safely truncate text to fit within an approximate token budget.\n *\n * Truncation is performed at sentence boundaries when possible to avoid\n * cutting mid-sentence. A suffix is appended to indicate that content\n * was removed.\n *\n * @param text      - The text to truncate.\n * @param maxTokens - The maximum number of tokens allowed.\n * @returns The (possibly truncated) text.\n *\n * @example\n * ```ts\n * truncateContext('A very long email body...', 500);\n * //  First ~2000 chars, ending at a sentence boundary + truncation notice\n * ```\n */\nexport function truncateContext(text: string, maxTokens: number): string {\n  if (!text) return text;\n  if (maxTokens <= 0) {\n    throw new Error('maxTokens must be a positive number.');\n  }\n\n  const maxChars = maxTokens * CHARS_PER_TOKEN;\n\n  // No truncation needed\n  if (text.length <= maxChars) {\n    return text;\n  }\n\n  // Reserve space for the truncation suffix\n  const availableChars = maxChars - TRUNCATION_SUFFIX.length;\n\n  if (availableChars <= 0) {\n    return TRUNCATION_SUFFIX.trim();\n  }\n\n  // Try to truncate at a sentence boundary\n  const slice = text.slice(0, availableChars);\n  const lastSentenceEnd = findLastSentenceBoundary(slice);\n\n  const truncated = lastSentenceEnd > 0 ? slice.slice(0, lastSentenceEnd) : slice;\n\n  return truncated.trimEnd() + TRUNCATION_SUFFIX;\n}\n\n/**\n * List all placeholder names found in a template.\n *\n * @param template - The prompt template string.\n * @returns An array of unique placeholder names (without braces).\n *\n * @example\n * ```ts\n * listPlaceholders('Hello {{NAME}}, your {{ITEM}} is {{STATUS}}.');\n * //  ['NAME', 'ITEM', 'STATUS']\n * ```\n */\nexport function listPlaceholders(template: string): string[] {\n  const matches = template.match(/\\{\\{([A-Z_][A-Z0-9_]*)\\}\\}/g);\n  if (!matches) return [];\n\n  const names = matches.map((m) => m.slice(2, -2));\n  return Array.from(new Set(names));\n}\n\n// ---------------------------------------------------------------------------\n// Internal helpers\n// ---------------------------------------------------------------------------\n\n/**\n * Find the index just after the last sentence-ending punctuation\n * (., !, or ?) in the given text.\n * Returns -1 if no sentence boundary is found.\n */\nfunction findLastSentenceBoundary(text: string): number {\n  // Match period, exclamation, or question mark followed by space or end-of-string\n  for (let i = text.length - 1; i >= 0; i--) {\n    const char = text[i];\n    if (char === '.' || char === '!' || char === '?') {\n      return i + 1;\n    }\n  }\n  return -1;\n}\n","/**\n * Glide  Add-in Commands (Function Commands)\n *\n * Registers ExecuteFunction handlers for compose-mode ribbon buttons.\n * These run silently (no taskpane) on the user's selected text:\n *   - Fix Grammar & Spelling\n *   - Improve Clarity\n *   - Make Concise\n *   - Make Professional\n *\n *  Rizonetech (Pty) Ltd.  https://rizonesoft.com\n */\n\n/* global Office */\n\nimport { generateText } from '../services/gemini';\nimport { buildPrompt } from '../prompts/builder';\nimport { IMPROVE_WRITING_PROMPT } from '../prompts/templates';\n\n// ---------------------------------------------------------------------------\n// Types\n// ---------------------------------------------------------------------------\n\ntype ImprovementFocus =\n  | 'fix_grammar'\n  | 'improve_clarity'\n  | 'make_concise'\n  | 'make_professional';\n\nconst FOCUS_LABELS: Record<ImprovementFocus, string> = {\n  fix_grammar: 'Fix grammar, spelling, and punctuation errors',\n  improve_clarity: 'Improve clarity and readability',\n  make_concise: 'Make the text more concise  remove unnecessary words',\n  make_professional: 'Make the tone more professional and polished',\n};\n\n// ---------------------------------------------------------------------------\n// Core helper  improve selected text in-place\n// ---------------------------------------------------------------------------\n\n/**\n * Read the selected text in compose mode, send it to Gemini with the given\n * improvement focus, and replace the selection with the improved version.\n */\nasync function improveSelectedText(\n  focus: ImprovementFocus,\n  event: Office.AddinCommands.Event,\n): Promise<void> {\n  const item = Office.context.mailbox.item;\n\n  if (!item) {\n    showNotification('No email is open.', event);\n    return;\n  }\n\n  try {\n    // 1. Read the selected text\n    const selectedText = await getSelectedText(item);\n\n    if (!selectedText.trim()) {\n      showNotification('Please select some text first.', event);\n      return;\n    }\n\n    // 2. Build the prompt and call Gemini\n    const focusLabel = FOCUS_LABELS[focus];\n    const prompt = buildPrompt(IMPROVE_WRITING_PROMPT, {\n      TEXT: selectedText,\n      IMPROVEMENT_FOCUS: focusLabel,\n    });\n\n    const improved = await generateText(prompt, {\n      temperature: 0.3,\n      maxOutputTokens: 2048,\n    });\n\n    // 3. Replace the selected text with the improved version\n    await setSelectedText(item, improved);\n\n    showNotification(' Text improved', event);\n  } catch (err: any) {\n    const message = err?.message || 'Failed to improve text.';\n    showNotification(`Error: ${message}`, event);\n  }\n}\n\n// ---------------------------------------------------------------------------\n// Office.js helpers\n// ---------------------------------------------------------------------------\n\nfunction getSelectedText(item: any): Promise<string> {\n  return new Promise((resolve, reject) => {\n    if (typeof item.getSelectedDataAsync !== 'function') {\n      reject(new Error('Selection API not available. Ensure you are in compose mode.'));\n      return;\n    }\n\n    item.getSelectedDataAsync(\n      Office.CoercionType.Text,\n      (result: Office.AsyncResult<any>) => {\n        if (result.status === Office.AsyncResultStatus.Succeeded) {\n          resolve(result.value?.data || '');\n        } else {\n          reject(new Error(result.error?.message || 'Failed to read selected text'));\n        }\n      },\n    );\n  });\n}\n\nfunction setSelectedText(item: any, text: string): Promise<void> {\n  return new Promise((resolve, reject) => {\n    if (!item.body || typeof item.body.setSelectedDataAsync !== 'function') {\n      reject(new Error('Cannot write to compose body.'));\n      return;\n    }\n\n    item.body.setSelectedDataAsync(\n      text,\n      { coercionType: Office.CoercionType.Text },\n      (result: Office.AsyncResult<void>) => {\n        if (result.status === Office.AsyncResultStatus.Succeeded) {\n          resolve();\n        } else {\n          reject(new Error(result.error?.message || 'Failed to replace text'));\n        }\n      },\n    );\n  });\n}\n\nfunction showNotification(message: string, event: Office.AddinCommands.Event): void {\n  const item = Office.context.mailbox.item;\n\n  if (item) {\n    item.notificationMessages.replaceAsync('GlideNotification', {\n      type: Office.MailboxEnums.ItemNotificationMessageType.InformationalMessage,\n      message,\n      icon: 'Icon.16x16',\n      persistent: false,\n    } as Office.NotificationMessageDetails);\n  }\n\n  event.completed();\n}\n\n// ---------------------------------------------------------------------------\n// Function command handlers\n// ---------------------------------------------------------------------------\n\nfunction fixGrammar(event: Office.AddinCommands.Event): void {\n  improveSelectedText('fix_grammar', event);\n}\n\nfunction improveClarity(event: Office.AddinCommands.Event): void {\n  improveSelectedText('improve_clarity', event);\n}\n\nfunction makeConcise(event: Office.AddinCommands.Event): void {\n  improveSelectedText('make_concise', event);\n}\n\nfunction makeProfessional(event: Office.AddinCommands.Event): void {\n  improveSelectedText('make_professional', event);\n}\n\n// ---------------------------------------------------------------------------\n// Initialization\n// ---------------------------------------------------------------------------\n\nOffice.onReady(() => {\n  // Register all function commands with Office\n  Office.actions.associate('fixGrammar', fixGrammar);\n  Office.actions.associate('improveClarity', improveClarity);\n  Office.actions.associate('makeConcise', makeConcise);\n  Office.actions.associate('makeProfessional', makeProfessional);\n});\n","/**\n * Glide  Prompt Templates\n *\n * Reusable prompt templates for all Glide AI features.\n * Each template uses {{PLACEHOLDER}} syntax for variable substitution\n * via the `buildPrompt` function in builder.ts.\n *\n *  Rizonetech (Pty) Ltd.  https://rizonesoft.com\n */\n\n// ---------------------------------------------------------------------------\n// Draft Email\n// ---------------------------------------------------------------------------\n\n/**\n * Compose a new email from bullet points or brief instructions.\n *\n * Placeholders: {{INSTRUCTIONS}}, {{TONE}}, {{LANGUAGE}}\n */\nexport const DRAFT_EMAIL_PROMPT = `You are a professional email assistant.\n\nDraft a complete email based on the following instructions:\n\n{{INSTRUCTIONS}}\n\nRequirements:\n- Tone: {{TONE}}\n- Language: {{LANGUAGE}}\n- Include a subject line on the first line prefixed with \"Subject: \"\n- Use appropriate greeting and sign-off\n- Keep the email concise and to the point\n- Do not add any commentary outside the email itself`;\n\n// ---------------------------------------------------------------------------\n// Reply\n// ---------------------------------------------------------------------------\n\n/**\n * Generate a reply to an existing email.\n *\n * Placeholders: {{ORIGINAL_EMAIL}}, {{REPLY_INSTRUCTIONS}}, {{TONE}}\n */\nexport const REPLY_PROMPT = `You are a professional email assistant.\n\nHere is the original email you are replying to:\n\n---\n{{ORIGINAL_EMAIL}}\n---\n\nReply instructions: {{REPLY_INSTRUCTIONS}}\n\nRequirements:\n- Tone: {{TONE}}\n- Write only the reply body (no subject line needed)\n- Reference relevant points from the original email naturally\n- Keep the reply focused and professional\n- Do not add any commentary outside the reply itself`;\n\n// ---------------------------------------------------------------------------\n// Summarize Thread\n// ---------------------------------------------------------------------------\n\n/**\n * Summarize a multi-message email thread.\n *\n * Placeholders: {{EMAIL_THREAD}}, {{SUMMARY_LENGTH}}\n */\nexport const SUMMARIZE_THREAD_PROMPT = `You are a professional email assistant.\n\nSummarize the following email thread:\n\n---\n{{EMAIL_THREAD}}\n---\n\nRequirements:\n- Length: {{SUMMARY_LENGTH}} (brief = 2-3 sentences, standard = 1 paragraph, detailed = multiple paragraphs)\n- Identify the key discussion points and decisions made\n- Note any action items or deadlines mentioned\n- List the participants and their main positions\n- Use bullet points for clarity where appropriate\n- Do not add opinions or information not present in the thread`;\n\n// ---------------------------------------------------------------------------\n// Improve Writing\n// ---------------------------------------------------------------------------\n\n/**\n * Improve grammar, clarity, and tone of selected text.\n *\n * Placeholders: {{TEXT}}, {{IMPROVEMENT_FOCUS}}\n */\nexport const IMPROVE_WRITING_PROMPT = `You are a professional writing assistant.\n\nImprove the following text:\n\n---\n{{TEXT}}\n---\n\nFocus on: {{IMPROVEMENT_FOCUS}}\n\nRequirements:\n- Fix grammar, spelling, and punctuation errors\n- Improve clarity and readability\n- Maintain the original meaning and intent\n- Keep the same general length unless brevity improves the text\n- Return only the improved text, no explanations or annotations`;\n\n// ---------------------------------------------------------------------------\n// Extract Action Items\n// ---------------------------------------------------------------------------\n\n/**\n * Pull tasks, deadlines, and responsibilities from emails.\n *\n * Placeholders: {{EMAIL_CONTENT}}\n */\nexport const EXTRACT_ACTION_ITEMS_PROMPT = `You are a professional email assistant.\n\nExtract all action items, tasks, and deadlines from the following email:\n\n---\n{{EMAIL_CONTENT}}\n---\n\nRequirements:\n- List each action item as a bullet point\n- For each item, identify:\n  - **Task**: What needs to be done\n  - **Owner**: Who is responsible (if mentioned)\n  - **Deadline**: When it's due (if mentioned)\n- If no action items are found, respond with \"No action items found.\"\n- Only extract items explicitly stated or clearly implied in the email\n- Do not invent tasks that are not present`;\n\n// ---------------------------------------------------------------------------\n// Translate\n// ---------------------------------------------------------------------------\n\n/**\n * Translate email content to a target language.\n *\n * Placeholders: {{TEXT}}, {{TARGET_LANGUAGE}}\n */\nexport const TRANSLATE_PROMPT = `You are a professional translator.\n\nTranslate the following text to {{TARGET_LANGUAGE}}:\n\n---\n{{TEXT}}\n---\n\nRequirements:\n- Maintain the original formatting (paragraphs, bullet points, etc.)\n- Preserve the original tone and register\n- Use natural, fluent phrasing in the target language (not literal word-for-word)\n- Keep proper nouns, brand names, and technical terms as-is unless they have\n  well-known translations\n- Return only the translated text, no explanations`;\n\n// ---------------------------------------------------------------------------\n// Change Tone\n// ---------------------------------------------------------------------------\n\n/**\n * Rewrite text in a different tone.\n *\n * Placeholders: {{TEXT}}, {{TARGET_TONE}}\n *\n * Supported tones: formal, casual, friendly, professional, assertive, empathetic\n */\nexport const CHANGE_TONE_PROMPT = `You are a professional writing assistant.\n\nRewrite the following text in a {{TARGET_TONE}} tone:\n\n---\n{{TEXT}}\n---\n\nRequirements:\n- Maintain the original meaning and all key information\n- Adjust vocabulary, sentence structure, and phrasing to match the target tone\n- Keep approximately the same length\n- Return only the rewritten text, no explanations or annotations`;\n"],"names":["SchemaType","ExecutableCodeLanguage","Outcome","HarmCategory","HarmBlockThreshold","HarmProbability","BlockReason","FinishReason","TaskType","FunctionCallingMode","DynamicRetrievalMode","Task","Error","RECITATION","SAFETY","LANGUAGE","SuppressedError","DEFAULT_SETTINGS","apiKey","defaultModel","defaultTone","defaultSummaryStyle","defaultLanguage","cached","getSetting","key","_objectSpread","raw","localStorage","getItem","parsed","JSON","parse","_unused","loadSettings","e","t","r","Symbol","n","iterator","o","toStringTag","i","c","prototype","Generator","u","Object","create","_regeneratorDefine2","f","p","y","G","v","a","d","bind","length","l","TypeError","call","done","value","return","GeneratorFunction","GeneratorFunctionPrototype","getPrototypeOf","setPrototypeOf","__proto__","displayName","_regenerator","w","m","defineProperty","_invoke","enumerable","configurable","writable","_typeof","constructor","asyncGeneratorStep","Promise","resolve","then","_asyncToGenerator","arguments","apply","_next","_throw","_wrapNativeSuper","Map","Function","toString","indexOf","_isNativeFunction","has","get","set","Wrapper","_isNativeReflectConstruct","Reflect","construct","push","_setPrototypeOf","_construct","_getPrototypeOf","Boolean","valueOf","GeminiErrorCode","GeminiError","_Error","message","code","_this","retryable","undefined","statusCode","_classCallCheck","ReferenceError","_assertThisInitialized","_possibleConstructorReturn","_callSuper","name","_inherits","getClient","INVALID_API_KEY","generateText","_x","_generateText","_callee","prompt","_ref","_options$model","_options$temperature","_options$maxOutputTok","_options$topP","_options$topK","options","client","modelName","generationConfig","model","_args","_context","temperature","maxOutputTokens","topP","topK","getGenerativeModel","retryWithBackoff","callModel","_x2","_x3","_callModel","_callee2","result","response","text","_context2","withTimeout","generateContent","trim","CONTENT_FILTERED","classifyError","promise","ms","reject","timer","setTimeout","concat","TIMEOUT","clearTimeout","catch","err","_x4","_retryWithBackoff","_callee3","fn","lastError","delay","attempt","jitter","_t2","_context3","Math","random","sleep","error","String","obj","status","resp","extractStatusCode","test","RATE_LIMITED","QUOTA_EXCEEDED","NETWORK_ERROR","UNKNOWN","buildPrompt","template","variables","_i","_Object$entries","entries","_Object$entries$_i","_slicedToArray","placeholder","split","join","FOCUS_LABELS","fix_grammar","improve_clarity","make_concise","make_professional","improveSelectedText","_improveSelectedText","focus","event","item","selectedText","improved","_t","Office","context","mailbox","showNotification","getSelectedText","TEXT","IMPROVEMENT_FOCUS","setSelectedText","getSelectedDataAsync","CoercionType","Text","_result$value","_result$error","AsyncResultStatus","Succeeded","data","body","setSelectedDataAsync","coercionType","_result$error2","notificationMessages","replaceAsync","type","MailboxEnums","ItemNotificationMessageType","InformationalMessage","icon","persistent","completed","fixGrammar","improveClarity","makeConcise","makeProfessional","onReady","actions","associate"],"sourceRoot":""}